{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Load a video file and create a prediction based on AI algorithm - LSTM\n",
    "##############################################################################\n",
    "\n",
    "# Please note - This script in under development and not working just yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize Core Packages\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import shutil\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data_dir\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Deep Learning Framework \n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Variables\n",
    "\n",
    "videoFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/\"\n",
    "videoFile = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/v_YoYo_g02_c02.avi\" #v_HorseRiding_g08_c06.avi or v_YoYo_g02_c02.avi\n",
    "imagesFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images\"\n",
    "algorithmFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/\"\n",
    "\n",
    "framerate_value = 30\n",
    "\n",
    "# The shape of the individual image is 3 layers of 240 pixels by 320 pixels\n",
    "\n",
    "horizontal_size = 240\n",
    "vertical_size = 320\n",
    "layer_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load old model weights and parameters\n",
    "\n",
    "validation_features = np.load(algorithmFolder + \"validation_features.npy\")\n",
    "validation_labels = np.load(algorithmFolder + \"validation_labels.npy\")\n",
    "train_features = np.load(algorithmFolder + \"train_features.npy\")\n",
    "train_labels = np.load(algorithmFolder + \"train_labels.npy\")\n",
    "features_rnn = np.load(algorithmFolder + \"features_rnn.npy\")\n",
    "labels_rnn = np.load(algorithmFolder + \"labels_rnn.npy\")\n",
    "features_rnn_v = np.load(algorithmFolder + \"features_rnn_v.np.npy\")\n",
    "labels_rnn_v = np.load(algorithmFolder + \"labels_rnn_v.np.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 images are extacted in C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images.\n"
     ]
    }
   ],
   "source": [
    "# This converts a video file into multiple images for scoring/prediction\n",
    "\n",
    "vidcap = cv2.VideoCapture(videoFile)\n",
    "count = 0\n",
    "while True:\n",
    "    #vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000)) # comment out for all frames\n",
    "    success,image = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(imagesFolder,\"frame{:d}.jpg\".format(count)), image)     # save frame as JPEG file\n",
    "    count += 1 # 1 represents once per second; 5 for every 5 seconds\n",
    "print(\"{} images are extacted in {}.\".format(count,imagesFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Inception 3 algorithm \n",
    "# from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will re-train the top layer of Inception with our own dataset. Thats why we define include_top to false\n",
    "# The shape of the individual image is 3 layers of 240 pixels by 320 pixels\n",
    "\n",
    "# conv_base = InceptionV3(weights='imagenet',\n",
    "#                        include_top=False,\n",
    "#                        input_shape=(horizontal_size, vertical_size, layer_count)\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/modeltestDK.h5') # model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               25166080  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 25,166,851\n",
      "Trainable params: 25,166,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the previously trained algorithm\n",
    "\n",
    "model = keras.models.load_model('C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/modeltestDK.h5') # model.h5\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model - we must do this before running predictions\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=2e-6),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will loop through the target folder, bring all of the photos into the mix, and preprocess them. \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "            # img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "            img = np.reshape(img,[1,horizontal_size,vertical_size,layer_count])\n",
    "            # img = np.reshape(img,[1, 6, 8, 2048])\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function and return all of the files\n",
    "\n",
    "img2 = load_images_from_folder(imagesFolder)\n",
    "# img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack up images list to pass for prediction\n",
    "\n",
    "images = np.vstack(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images\n",
    "\n",
    "batch_size_pictures = len(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from the images using pretrained model\n",
    "images = conv_base.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the images to 1-D form\n",
    "images = images.reshape(batch_size_pictures, 6*8*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 2.92647580e-23 6.25931251e-11]\n",
      " [1.00000000e+00 2.22746662e-23 8.23320578e-11]\n",
      " [9.94473755e-01 3.24770030e-19 5.52618690e-03]\n",
      " [9.99999404e-01 1.42404668e-17 5.54767837e-07]\n",
      " [9.99958038e-01 1.81071676e-16 4.19897151e-05]\n",
      " [9.99974847e-01 6.60585114e-16 2.52102691e-05]\n",
      " [9.87298667e-01 4.93024990e-17 1.27013316e-02]\n",
      " [9.99662042e-01 4.20823008e-18 3.37935140e-04]\n",
      " [9.99306321e-01 6.58261812e-18 6.93628506e-04]\n",
      " [9.99989986e-01 3.79506484e-19 9.96677954e-06]\n",
      " [9.99976873e-01 5.38290937e-19 2.31606064e-05]\n",
      " [9.99889612e-01 1.01343966e-18 1.10334011e-04]\n",
      " [9.99999881e-01 1.59628684e-18 1.08333467e-07]\n",
      " [9.99924421e-01 1.77168736e-19 7.56222726e-05]\n",
      " [9.99993920e-01 1.69768636e-18 6.03911940e-06]\n",
      " [9.86538291e-01 7.66059658e-18 1.34616746e-02]\n",
      " [1.29505917e-01 4.36657520e-18 8.70494127e-01]\n",
      " [9.82800245e-01 9.25709404e-17 1.71997789e-02]\n",
      " [9.75253940e-01 1.14274274e-16 2.47460455e-02]\n",
      " [8.43869567e-01 4.76258436e-17 1.56130388e-01]\n",
      " [2.88240034e-02 2.26664640e-16 9.71175969e-01]\n",
      " [2.22146697e-02 1.80419354e-16 9.77785349e-01]\n",
      " [7.97258735e-01 5.67144409e-17 2.02741325e-01]\n",
      " [6.85987651e-01 3.80722781e-18 3.14012349e-01]\n",
      " [9.79266107e-01 1.00401528e-16 2.07339283e-02]\n",
      " [4.45036262e-01 6.77324809e-18 5.54963708e-01]\n",
      " [2.52423465e-01 1.09618218e-14 7.47576535e-01]\n",
      " [9.99972343e-01 1.17024550e-16 2.76947558e-05]\n",
      " [9.99097347e-01 1.69383098e-17 9.02628060e-04]\n",
      " [9.98742878e-01 1.45501351e-17 1.25714706e-03]\n",
      " [9.99999404e-01 5.91610228e-17 5.69005294e-07]\n",
      " [4.79642689e-01 6.56026647e-16 5.20357311e-01]\n",
      " [5.04422467e-04 4.02589269e-19 9.99495506e-01]\n",
      " [2.81224656e-03 9.01980074e-18 9.97187793e-01]\n",
      " [1.89779475e-01 9.95333924e-17 8.10220480e-01]\n",
      " [9.78254795e-01 2.78159500e-15 2.17451826e-02]\n",
      " [1.63322136e-01 8.37296899e-17 8.36677909e-01]\n",
      " [9.82289255e-01 5.35382726e-14 1.77107733e-02]\n",
      " [9.70015109e-01 8.83132204e-14 2.99848989e-02]\n",
      " [9.75917280e-01 7.27213361e-14 2.40827296e-02]\n",
      " [9.99999881e-01 5.16151636e-17 1.64520330e-07]\n",
      " [9.99999762e-01 1.25112069e-17 2.17550692e-07]\n",
      " [1.00000000e+00 3.91661619e-20 1.29349118e-08]\n",
      " [1.00000000e+00 3.67743414e-23 1.01409958e-09]\n",
      " [1.00000000e+00 5.14884829e-26 9.94619248e-11]\n",
      " [1.00000000e+00 2.17182795e-24 2.99572460e-13]\n",
      " [9.46842492e-01 1.30751892e-15 5.31574637e-02]\n",
      " [1.00000000e+00 2.90147459e-24 3.64023590e-13]\n",
      " [9.99952316e-01 1.33661143e-20 4.76262503e-05]\n",
      " [9.99964952e-01 1.06638905e-20 3.49982438e-05]\n",
      " [9.94202554e-01 1.59641903e-19 5.79738431e-03]\n",
      " [9.99684215e-01 2.72836716e-18 3.15848592e-04]\n",
      " [9.99090552e-01 4.37009692e-18 9.09496157e-04]\n",
      " [3.19639683e-01 6.17624579e-18 6.80360377e-01]\n",
      " [9.92596269e-01 1.47070206e-19 7.40368292e-03]\n",
      " [1.00000000e+00 2.23775479e-23 8.67416916e-10]\n",
      " [1.00000000e+00 3.18844767e-23 3.76064291e-09]\n",
      " [9.04959679e-01 1.25487931e-15 9.50402766e-02]\n",
      " [1.00000000e+00 7.47358744e-23 1.28978717e-10]\n",
      " [1.00000000e+00 1.36739314e-19 4.11160580e-13]\n",
      " [1.00000000e+00 1.17356198e-19 9.38173584e-13]\n",
      " [9.99999404e-01 3.31691711e-21 5.53443556e-07]\n",
      " [8.13414231e-02 3.66232209e-23 9.18658614e-01]\n",
      " [2.19716594e-01 9.19240933e-23 7.80283391e-01]\n",
      " [1.26174390e-02 2.77544143e-24 9.87382591e-01]\n",
      " [4.44728183e-03 9.94811681e-25 9.95552719e-01]\n",
      " [4.73441184e-03 1.28716777e-24 9.95265603e-01]\n",
      " [1.11611530e-01 4.99678598e-25 8.88388455e-01]\n",
      " [7.79429600e-02 2.22408965e-17 9.22056973e-01]\n",
      " [4.76785690e-01 1.35622939e-23 5.23214340e-01]\n",
      " [9.90074694e-01 3.97817833e-18 9.92529839e-03]\n",
      " [7.98845053e-01 1.90634505e-18 2.01154992e-01]\n",
      " [2.75397003e-01 3.52935155e-20 7.24602938e-01]\n",
      " [9.99982476e-01 1.12084985e-16 1.75457426e-05]\n",
      " [9.99991059e-01 1.14233007e-16 8.99027691e-06]\n",
      " [1.00000000e+00 2.74285998e-18 3.13389457e-08]\n",
      " [9.99999762e-01 1.79939527e-17 2.51714027e-07]\n",
      " [1.00000000e+00 1.26350908e-18 3.62771480e-11]\n",
      " [1.00000000e+00 6.83375647e-16 2.04708925e-08]\n",
      " [1.76286414e-01 3.79836209e-17 8.23713541e-01]\n",
      " [1.00000000e+00 6.08314869e-16 2.13024443e-08]\n",
      " [1.00000000e+00 7.43499845e-16 4.28329727e-08]\n",
      " [9.99987483e-01 1.97690997e-18 1.25015167e-05]\n",
      " [9.99951601e-01 7.78084050e-21 4.83792610e-05]\n",
      " [9.99962568e-01 9.92571983e-21 3.73932780e-05]\n",
      " [1.00000000e+00 1.39190518e-22 1.07646292e-08]\n",
      " [1.00000000e+00 4.20622528e-22 2.57444532e-09]\n",
      " [1.00000000e+00 7.92210664e-21 3.44902357e-10]\n",
      " [1.00000000e+00 2.97409687e-20 1.63590208e-09]\n",
      " [9.99997973e-01 9.74757647e-20 2.02150409e-06]\n",
      " [6.68451563e-02 4.64255615e-17 9.33154881e-01]\n",
      " [9.99990940e-01 2.00856100e-19 9.11529332e-06]\n",
      " [9.97035265e-01 3.74482163e-19 2.96473107e-03]\n",
      " [9.99752462e-01 4.24845107e-19 2.47581309e-04]\n",
      " [9.99741733e-01 4.23992180e-19 2.58303015e-04]\n",
      " [9.99469340e-01 1.85342741e-18 5.30693855e-04]\n",
      " [9.99613345e-01 2.18081309e-19 3.86665459e-04]\n",
      " [9.99668360e-01 5.08742346e-20 3.31623043e-04]\n",
      " [9.99567330e-01 1.61947343e-20 4.32612083e-04]\n",
      " [8.05152237e-01 8.29200310e-16 1.94847777e-01]\n",
      " [9.99999762e-01 3.24947508e-22 1.98006617e-07]\n",
      " [9.98902917e-01 4.77616150e-16 1.09707436e-03]\n",
      " [9.98892009e-01 3.84856063e-16 1.10806769e-03]\n",
      " [9.99326825e-01 1.43714354e-15 6.73222297e-04]\n",
      " [9.99618649e-01 1.51575349e-15 3.81284626e-04]\n",
      " [9.99998450e-01 1.04202068e-17 1.54897089e-06]\n",
      " [9.99998212e-01 4.46994465e-18 1.78192602e-06]\n",
      " [6.42109096e-01 5.07727066e-17 3.57890934e-01]\n",
      " [3.24583240e-02 3.38246209e-18 9.67541695e-01]\n",
      " [4.45000529e-02 2.82269528e-17 9.55499887e-01]\n",
      " [3.14666688e-01 6.01420540e-15 6.85333312e-01]\n",
      " [9.99998927e-01 1.99611800e-20 1.04550702e-06]\n",
      " [1.53021351e-01 4.80685184e-15 8.46978664e-01]\n",
      " [1.74842030e-01 5.84499717e-17 8.25158000e-01]\n",
      " [1.46854427e-02 1.72978719e-17 9.85314608e-01]\n",
      " [8.78046174e-03 7.49053486e-18 9.91219580e-01]\n",
      " [7.99959525e-03 6.79547071e-18 9.92000341e-01]\n",
      " [4.94297128e-03 1.54266091e-17 9.95056987e-01]\n",
      " [7.33370721e-01 1.56954527e-17 2.66629249e-01]\n",
      " [9.81453300e-01 6.41237519e-20 1.85467210e-02]\n",
      " [8.81358564e-01 1.64370352e-20 1.18641444e-01]\n",
      " [8.67817283e-01 1.46891186e-20 1.32182732e-01]\n",
      " [9.99970555e-01 8.20686792e-20 2.94718102e-05]\n",
      " [3.68302949e-02 1.72929231e-18 9.63169694e-01]\n",
      " [4.15257849e-02 1.76795377e-16 9.58474159e-01]\n",
      " [9.17147659e-03 2.45506412e-17 9.90828514e-01]\n",
      " [1.10310561e-04 9.51621044e-19 9.99889731e-01]\n",
      " [9.89750922e-01 1.00006258e-15 1.02490708e-02]\n",
      " [9.99582589e-01 8.95079216e-19 4.17472562e-04]\n",
      " [9.99409437e-01 4.26564919e-19 5.90586278e-04]\n",
      " [9.99734461e-01 8.78915073e-20 2.65487324e-04]\n",
      " [7.14257002e-01 9.38653705e-18 2.85742968e-01]\n",
      " [9.02757645e-01 1.69242361e-17 9.72423628e-02]\n",
      " [9.99965906e-01 6.67462570e-20 3.41410159e-05]\n",
      " [5.35422284e-03 1.65277916e-17 9.94645834e-01]\n",
      " [1.89977884e-01 1.73717524e-16 8.10022056e-01]\n",
      " [8.04957509e-01 4.97145702e-15 1.95042461e-01]\n",
      " [1.73449919e-01 4.24459936e-16 8.26550066e-01]\n",
      " [9.89474893e-01 7.41254546e-17 1.05250478e-02]\n",
      " [9.73232925e-01 6.82860757e-17 2.67670713e-02]\n",
      " [7.90076852e-01 5.35503335e-15 2.09923103e-01]\n",
      " [6.98197663e-01 1.32517449e-14 3.01802367e-01]\n",
      " [7.64733970e-01 2.00719670e-14 2.35266030e-01]\n",
      " [5.78906238e-01 5.45812149e-18 4.21093792e-01]\n",
      " [9.99708116e-01 5.50903338e-21 2.91908946e-04]\n",
      " [9.96348321e-01 3.13199495e-15 3.65169719e-03]\n",
      " [1.87140509e-01 3.25195718e-18 8.12859476e-01]\n",
      " [4.26076865e-03 1.32599013e-17 9.95739222e-01]\n",
      " [1.00000000e+00 1.21757388e-17 6.58788357e-09]\n",
      " [1.00000000e+00 5.31085315e-18 4.32860547e-09]\n",
      " [9.99993205e-01 8.23482056e-17 6.80374023e-06]\n",
      " [2.54677003e-03 1.55228179e-15 9.97453272e-01]\n",
      " [2.17461539e-03 2.11188078e-15 9.97825384e-01]\n",
      " [2.51213342e-01 2.42505453e-16 7.48786688e-01]\n",
      " [9.39840436e-01 5.09475387e-18 6.01595677e-02]\n",
      " [9.99196231e-01 3.67026759e-20 8.03741917e-04]\n",
      " [9.31001484e-01 7.99702913e-18 6.89985231e-02]\n",
      " [8.96772742e-01 4.68648358e-18 1.03227213e-01]\n",
      " [9.55319822e-01 4.71359194e-18 4.46802229e-02]\n",
      " [9.83311057e-01 2.28556559e-18 1.66888889e-02]\n",
      " [9.69596326e-01 1.90629893e-18 3.04036979e-02]\n",
      " [9.04722333e-01 2.91695668e-18 9.52776745e-02]\n",
      " [4.58115280e-01 9.44466862e-19 5.41884780e-01]\n",
      " [9.99409556e-01 3.26464122e-19 5.90401993e-04]\n",
      " [9.99796212e-01 2.04388329e-19 2.03793112e-04]\n",
      " [9.67343032e-01 2.21452648e-20 3.26570421e-02]\n",
      " [9.96802568e-01 1.73757404e-19 3.19747510e-03]\n",
      " [9.42359507e-01 2.39762420e-20 5.76404780e-02]\n",
      " [9.24177766e-01 1.10933589e-17 7.58222193e-02]\n",
      " [9.99789536e-01 4.60860452e-18 2.10424099e-04]\n",
      " [9.99610603e-01 5.66038494e-18 3.89385910e-04]\n",
      " [9.99631405e-01 3.95019068e-18 3.68602807e-04]\n",
      " [9.91087854e-01 3.10196038e-17 8.91215447e-03]\n",
      " [9.99985099e-01 8.31018265e-15 1.49352336e-05]\n",
      " [9.98774469e-01 1.53412263e-13 1.22552493e-03]\n",
      " [9.45331812e-01 1.55208979e-14 5.46681210e-02]\n",
      " [9.59956288e-01 1.22972752e-14 4.00436707e-02]\n",
      " [9.97150838e-01 1.75511829e-19 2.84918747e-03]\n",
      " [9.99999881e-01 3.64848921e-19 8.47810568e-08]\n",
      " [9.99999166e-01 6.00749484e-19 8.15763713e-07]\n",
      " [9.99998212e-01 4.98720891e-19 1.80136169e-06]\n",
      " [9.99999762e-01 6.71162200e-19 2.45585682e-07]\n",
      " [1.00000000e+00 5.21120994e-19 1.45442227e-08]\n",
      " [1.00000000e+00 6.77291350e-19 2.72307599e-08]\n",
      " [1.00000000e+00 2.49297502e-19 1.34595401e-09]\n",
      " [1.00000000e+00 7.58260473e-21 5.40080394e-12]\n",
      " [1.00000000e+00 6.36499041e-19 1.32750859e-08]\n",
      " [1.00000000e+00 7.21569914e-19 1.17001715e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Create the prediction from our trained model\n",
    "\n",
    "probability = model.predict(images, batch_size=batch_size_pictures) # batch =1\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify the maximum percentage value of the prediction\n",
    "\n",
    "np.argmax(probability)  #0 is horse race, 1 is horse riding, 2 is yoyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HorseRace   HorseRiding          YoYo\n",
      "0     1.000000  2.926476e-23  6.259313e-11\n",
      "1     1.000000  2.227467e-23  8.233206e-11\n",
      "2     0.994474  3.247700e-19  5.526187e-03\n",
      "3     0.999999  1.424047e-17  5.547678e-07\n",
      "4     0.999958  1.810717e-16  4.198972e-05\n",
      "5     0.999975  6.605851e-16  2.521027e-05\n",
      "6     0.987299  4.930250e-17  1.270133e-02\n",
      "7     0.999662  4.208230e-18  3.379351e-04\n",
      "8     0.999306  6.582618e-18  6.936285e-04\n",
      "9     0.999990  3.795065e-19  9.966780e-06\n",
      "10    0.999977  5.382909e-19  2.316061e-05\n",
      "11    0.999890  1.013440e-18  1.103340e-04\n",
      "12    1.000000  1.596287e-18  1.083335e-07\n",
      "13    0.999924  1.771687e-19  7.562227e-05\n",
      "14    0.999994  1.697686e-18  6.039119e-06\n",
      "15    0.986538  7.660597e-18  1.346167e-02\n",
      "16    0.129506  4.366575e-18  8.704941e-01\n",
      "17    0.982800  9.257094e-17  1.719978e-02\n",
      "18    0.975254  1.142743e-16  2.474605e-02\n",
      "19    0.843870  4.762584e-17  1.561304e-01\n",
      "20    0.028824  2.266646e-16  9.711760e-01\n",
      "21    0.022215  1.804194e-16  9.777853e-01\n",
      "22    0.797259  5.671444e-17  2.027413e-01\n",
      "23    0.685988  3.807228e-18  3.140123e-01\n",
      "24    0.979266  1.004015e-16  2.073393e-02\n",
      "25    0.445036  6.773248e-18  5.549637e-01\n",
      "26    0.252423  1.096182e-14  7.475765e-01\n",
      "27    0.999972  1.170245e-16  2.769476e-05\n",
      "28    0.999097  1.693831e-17  9.026281e-04\n",
      "29    0.998743  1.455014e-17  1.257147e-03\n",
      "..         ...           ...           ...\n",
      "158   0.955320  4.713592e-18  4.468022e-02\n",
      "159   0.983311  2.285566e-18  1.668889e-02\n",
      "160   0.969596  1.906299e-18  3.040370e-02\n",
      "161   0.904722  2.916957e-18  9.527767e-02\n",
      "162   0.458115  9.444669e-19  5.418848e-01\n",
      "163   0.999410  3.264641e-19  5.904020e-04\n",
      "164   0.999796  2.043883e-19  2.037931e-04\n",
      "165   0.967343  2.214526e-20  3.265704e-02\n",
      "166   0.996803  1.737574e-19  3.197475e-03\n",
      "167   0.942360  2.397624e-20  5.764048e-02\n",
      "168   0.924178  1.109336e-17  7.582222e-02\n",
      "169   0.999790  4.608605e-18  2.104241e-04\n",
      "170   0.999611  5.660385e-18  3.893859e-04\n",
      "171   0.999631  3.950191e-18  3.686028e-04\n",
      "172   0.991088  3.101960e-17  8.912154e-03\n",
      "173   0.999985  8.310183e-15  1.493523e-05\n",
      "174   0.998774  1.534123e-13  1.225525e-03\n",
      "175   0.945332  1.552090e-14  5.466812e-02\n",
      "176   0.959956  1.229728e-14  4.004367e-02\n",
      "177   0.997151  1.755118e-19  2.849187e-03\n",
      "178   1.000000  3.648489e-19  8.478106e-08\n",
      "179   0.999999  6.007495e-19  8.157637e-07\n",
      "180   0.999998  4.987209e-19  1.801362e-06\n",
      "181   1.000000  6.711622e-19  2.455857e-07\n",
      "182   1.000000  5.211210e-19  1.454422e-08\n",
      "183   1.000000  6.772913e-19  2.723076e-08\n",
      "184   1.000000  2.492975e-19  1.345954e-09\n",
      "185   1.000000  7.582605e-21  5.400804e-12\n",
      "186   1.000000  6.364990e-19  1.327509e-08\n",
      "187   1.000000  7.215699e-19  1.170017e-08\n",
      "\n",
      "[188 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the probabilities\n",
    "\n",
    "PredictionResults = pd.DataFrame(probability, columns=['HorseRace','HorseRiding','YoYo'])\n",
    "# PredictionResults = pd.DataFrame(classes)\n",
    "\n",
    "print(PredictionResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 2 2 0 0 0 0 2 2 2 2 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 0 0 2 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 0 2 2 2 2 2 2 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 0 0 0 2 2\n",
      " 0 0 0 2 2 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Create the prediction\n",
    "\n",
    "classes = model.predict_classes(images, batch_size=1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     classification\n",
      "0                 0\n",
      "1                 0\n",
      "2                 0\n",
      "3                 0\n",
      "4                 0\n",
      "5                 0\n",
      "6                 0\n",
      "7                 0\n",
      "8                 0\n",
      "9                 0\n",
      "10                0\n",
      "11                0\n",
      "12                0\n",
      "13                0\n",
      "14                0\n",
      "15                0\n",
      "16                2\n",
      "17                0\n",
      "18                0\n",
      "19                0\n",
      "20                2\n",
      "21                2\n",
      "22                0\n",
      "23                0\n",
      "24                0\n",
      "25                2\n",
      "26                2\n",
      "27                0\n",
      "28                0\n",
      "29                0\n",
      "..              ...\n",
      "158               0\n",
      "159               0\n",
      "160               0\n",
      "161               0\n",
      "162               2\n",
      "163               0\n",
      "164               0\n",
      "165               0\n",
      "166               0\n",
      "167               0\n",
      "168               0\n",
      "169               0\n",
      "170               0\n",
      "171               0\n",
      "172               0\n",
      "173               0\n",
      "174               0\n",
      "175               0\n",
      "176               0\n",
      "177               0\n",
      "178               0\n",
      "179               0\n",
      "180               0\n",
      "181               0\n",
      "182               0\n",
      "183               0\n",
      "184               0\n",
      "185               0\n",
      "186               0\n",
      "187               0\n",
      "\n",
      "[188 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the classes\n",
    "\n",
    "PredictionClassResults = pd.DataFrame(classes, columns=['classification'])\n",
    "# PredictionClassResults = pd.DataFrame(classes)\n",
    "\n",
    "print(PredictionClassResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a dataframe with all of the file names in the folder\n",
    "\n",
    "filelist = os.listdir(imagesFolder)\n",
    "\n",
    "# path = os.path.join(os.getcwd(),'C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images/')\n",
    "# files = [os.path.join(path,i) for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the file listing into a dataframe\n",
    "\n",
    "filelisting = pd.DataFrame(filelist, columns=['FileName'])\n",
    "# filelisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_YoYo_g02_c02.avi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will identify the video in the folder\n",
    "\n",
    "videofilelist = [ f for f in listdir(videoFolder) if isfile(join(videoFolder,f)) ]\n",
    "videofilelist\n",
    "\n",
    "# path = os.path.join(os.getcwd(),videoFolder)\n",
    "#files = [os.path.join(path,i) for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the video file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults.loc[:, 'VideoName'] = videofilelist\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the image file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults['FileName'] = filelisting['FileName']\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults['classification'] = PredictionClassResults['classification']\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the date to the main prediction dataframe\n",
    "\n",
    "PredictionResults['DateTime'] = dt.datetime.now()\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the Order of the Dataframe to look nicer.\n",
    "\n",
    "PredictionResults = PredictionResults[['VideoName','FileName','DateTime','HorseRace','HorseRiding','YoYo','classification']]\n",
    "\n",
    "#cols = PredictionResults.columns.tolist()\n",
    "#cols = cols[-1:] + cols[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe into a csv file\n",
    "\n",
    "export_csv = PredictionResults.to_csv(r'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Results/PredictionResults.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and remove old files that will not be used\n",
    "\n",
    "for the_file in os.listdir(imagesFolder):\n",
    "    file_path = os.path.join(imagesFolder, the_file)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single image to test\n",
    "\n",
    "# img = cv2.imread('C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images/frame7.jpg') #frame7\n",
    "# img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "# img = np.reshape(img,[1,horizontal_size,vertical_size,layer_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = model.predict(img)\n",
    "# classes = model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    \"\"\"After predicting on each batch, check that batch's\n",
    "    accuracy to make sure things are good to go. This is\n",
    "    a simple accuracy metric, and so doesn't take confidence\n",
    "    into account, which would be a better metric to use to\n",
    "    compare changes in the model.\"\"\"\n",
    "    correct = 0\n",
    "    for frame in predictions:\n",
    "        # Get the highest confidence class.\n",
    "        this_prediction = frame[0].tolist()\n",
    "        this_label = frame[1]\n",
    "\n",
    "        max_value = max(this_prediction)\n",
    "        max_index = this_prediction.index(max_value)\n",
    "        predicted_label = labels[max_index]\n",
    "\n",
    "        # Now see if it matches.\n",
    "        if predicted_label == this_label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(predictions)\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
