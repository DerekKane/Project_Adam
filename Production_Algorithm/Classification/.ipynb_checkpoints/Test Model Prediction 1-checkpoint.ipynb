{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Load a video file and create a prediction based on AI algorithm\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize Core Packages\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import shutil\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data_dir\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Deep Learning Framework \n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Variables\n",
    "\n",
    "videoFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/\"\n",
    "videoFile = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/v_YoYo_g02_c03.avi\" #v_HorseRiding_g13_c01.avi\n",
    "imagesFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images\"\n",
    "algorithmFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/\"\n",
    "\n",
    "framerate_value = 30\n",
    "\n",
    "# The shape of the individual image is 3 layers of 240 pixels by 320 pixels\n",
    "\n",
    "horizontal_size = 240\n",
    "vertical_size = 320\n",
    "layer_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load old model weights and parameters\n",
    "\n",
    "validation_features = np.load(algorithmFolder + \"validation_features.npy\")\n",
    "validation_labels = np.load(algorithmFolder + \"validation_labels.npy\")\n",
    "train_features = np.load(algorithmFolder + \"train_features.npy\")\n",
    "train_labels = np.load(algorithmFolder + \"train_labels.npy\")\n",
    "features_rnn = np.load(algorithmFolder + \"features_rnn.npy\")\n",
    "labels_rnn = np.load(algorithmFolder + \"labels_rnn.npy\")\n",
    "features_rnn_v = np.load(algorithmFolder + \"features_rnn_v.np.npy\")\n",
    "labels_rnn_v = np.load(algorithmFolder + \"labels_rnn_v.np.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 images are extacted in C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images.\n"
     ]
    }
   ],
   "source": [
    "# This converts a video file into multiple images for scoring/prediction\n",
    "\n",
    "vidcap = cv2.VideoCapture(videoFile)\n",
    "count = 0\n",
    "while True:\n",
    "    #vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000)) # comment out for all frames\n",
    "    success,image = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(os.path.join(imagesFolder,\"frame{:d}.jpg\".format(count)), image)     # save frame as JPEG file\n",
    "    count += 1 # 1 represents once per second; 5 for every 5 seconds\n",
    "print(\"{} images are extacted in {}.\".format(count,imagesFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_95 (Conv2D)           (None, 238, 318, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 238, 318, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 119, 159, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 119, 159, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 117, 157, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 117, 157, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 58, 78, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 58, 78, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 56, 76, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 56, 76, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56, 76, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 544768)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               69730432  \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 69,824,067\n",
      "Trainable params: 69,824,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the previously trained algorithm\n",
    "\n",
    "model = keras.models.load_model('C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/modeltestDK.h5') # model.h5\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model - we must do this before running predictions\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=2e-6),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will loop through the target folder, bring all of the photos into the mix, and preprocess them. \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "            #img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "            img = np.reshape(img,[1,horizontal_size,vertical_size,layer_count])\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function and return all of the files\n",
    "\n",
    "img2 = load_images_from_folder(imagesFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack up images list to pass for prediction\n",
    "\n",
    "images = np.vstack(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images\n",
    "\n",
    "batch_size_pictures = len(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.5972499e-25 0.0000000e+00]\n",
      " [1.0000000e+00 7.7784372e-26 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [2.4652041e-05 9.9997532e-01 0.0000000e+00]\n",
      " [1.0000000e+00 8.3298550e-38 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [6.7286454e-19 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.1584396e-12 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.5864488e-20 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.1439187e-10 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [2.2732194e-04 9.9977273e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.3230744e-08 0.0000000e+00]\n",
      " [1.0000000e+00 1.0324689e-28 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.6968522e-33 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.7763055e-30 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.3214484e-27 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.4219461e-30 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [9.9288481e-01 7.1151736e-03 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [6.2122621e-33 1.0000000e+00 0.0000000e+00]\n",
      " [3.7289570e-36 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 8.9658295e-37 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.8231334e-37 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [2.7171684e-33 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create the prediction\n",
    "\n",
    "probability = model.predict(images, batch_size=batch_size_pictures) # batch =1\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify the maximum percentage value of the prediction\n",
    "\n",
    "np.argmax(probability)  #0 is horse race, 1 is horse riding, 2 is yoyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HorseRace   HorseRiding  YoYo\n",
      "0    1.000000e+00  1.597250e-25   0.0\n",
      "1    1.000000e+00  7.778437e-26   0.0\n",
      "2    1.000000e+00  0.000000e+00   0.0\n",
      "3    1.000000e+00  0.000000e+00   0.0\n",
      "4    0.000000e+00  1.000000e+00   0.0\n",
      "5    0.000000e+00  1.000000e+00   0.0\n",
      "6    0.000000e+00  1.000000e+00   0.0\n",
      "7    0.000000e+00  1.000000e+00   0.0\n",
      "8    0.000000e+00  1.000000e+00   0.0\n",
      "9    0.000000e+00  1.000000e+00   0.0\n",
      "10   0.000000e+00  1.000000e+00   0.0\n",
      "11   2.465204e-05  9.999753e-01   0.0\n",
      "12   1.000000e+00  8.329855e-38   0.0\n",
      "13   1.000000e+00  0.000000e+00   0.0\n",
      "14   1.000000e+00  0.000000e+00   0.0\n",
      "15   1.000000e+00  0.000000e+00   0.0\n",
      "16   1.000000e+00  0.000000e+00   0.0\n",
      "17   6.728645e-19  1.000000e+00   0.0\n",
      "18   1.000000e+00  5.158440e-12   0.0\n",
      "19   1.000000e+00  0.000000e+00   0.0\n",
      "20   1.000000e+00  0.000000e+00   0.0\n",
      "21   1.000000e+00  0.000000e+00   0.0\n",
      "22   1.000000e+00  0.000000e+00   0.0\n",
      "23   1.000000e+00  0.000000e+00   0.0\n",
      "24   1.000000e+00  0.000000e+00   0.0\n",
      "25   1.000000e+00  9.586449e-20   0.0\n",
      "26   1.000000e+00  0.000000e+00   0.0\n",
      "27   1.000000e+00  0.000000e+00   0.0\n",
      "28   1.000000e+00  0.000000e+00   0.0\n",
      "29   1.000000e+00  0.000000e+00   0.0\n",
      "..            ...           ...   ...\n",
      "136  1.000000e+00  0.000000e+00   0.0\n",
      "137  1.000000e+00  0.000000e+00   0.0\n",
      "138  1.000000e+00  6.823133e-37   0.0\n",
      "139  1.000000e+00  0.000000e+00   0.0\n",
      "140  1.000000e+00  0.000000e+00   0.0\n",
      "141  1.000000e+00  0.000000e+00   0.0\n",
      "142  1.000000e+00  0.000000e+00   0.0\n",
      "143  1.000000e+00  0.000000e+00   0.0\n",
      "144  0.000000e+00  1.000000e+00   0.0\n",
      "145  1.000000e+00  0.000000e+00   0.0\n",
      "146  1.000000e+00  0.000000e+00   0.0\n",
      "147  1.000000e+00  0.000000e+00   0.0\n",
      "148  1.000000e+00  0.000000e+00   0.0\n",
      "149  1.000000e+00  0.000000e+00   0.0\n",
      "150  1.000000e+00  0.000000e+00   0.0\n",
      "151  1.000000e+00  0.000000e+00   0.0\n",
      "152  1.000000e+00  0.000000e+00   0.0\n",
      "153  1.000000e+00  0.000000e+00   0.0\n",
      "154  1.000000e+00  0.000000e+00   0.0\n",
      "155  2.717168e-33  1.000000e+00   0.0\n",
      "156  1.000000e+00  0.000000e+00   0.0\n",
      "157  1.000000e+00  0.000000e+00   0.0\n",
      "158  1.000000e+00  0.000000e+00   0.0\n",
      "159  1.000000e+00  0.000000e+00   0.0\n",
      "160  1.000000e+00  0.000000e+00   0.0\n",
      "161  1.000000e+00  0.000000e+00   0.0\n",
      "162  1.000000e+00  0.000000e+00   0.0\n",
      "163  1.000000e+00  0.000000e+00   0.0\n",
      "164  1.000000e+00  0.000000e+00   0.0\n",
      "165  1.000000e+00  0.000000e+00   0.0\n",
      "\n",
      "[166 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the probabilities\n",
    "\n",
    "PredictionResults = pd.DataFrame(probability, columns=['HorseRace','HorseRiding','YoYo'])\n",
    "# PredictionResults = pd.DataFrame(classes)\n",
    "\n",
    "print(PredictionResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Create the prediction\n",
    "\n",
    "classes = model.predict_classes(images, batch_size=1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     classification\n",
      "0                 0\n",
      "1                 0\n",
      "2                 0\n",
      "3                 0\n",
      "4                 1\n",
      "5                 1\n",
      "6                 1\n",
      "7                 1\n",
      "8                 1\n",
      "9                 1\n",
      "10                1\n",
      "11                1\n",
      "12                0\n",
      "13                0\n",
      "14                0\n",
      "15                0\n",
      "16                0\n",
      "17                1\n",
      "18                0\n",
      "19                0\n",
      "20                0\n",
      "21                0\n",
      "22                0\n",
      "23                0\n",
      "24                0\n",
      "25                0\n",
      "26                0\n",
      "27                0\n",
      "28                0\n",
      "29                0\n",
      "..              ...\n",
      "136               0\n",
      "137               0\n",
      "138               0\n",
      "139               0\n",
      "140               0\n",
      "141               0\n",
      "142               0\n",
      "143               0\n",
      "144               1\n",
      "145               0\n",
      "146               0\n",
      "147               0\n",
      "148               0\n",
      "149               0\n",
      "150               0\n",
      "151               0\n",
      "152               0\n",
      "153               0\n",
      "154               0\n",
      "155               1\n",
      "156               0\n",
      "157               0\n",
      "158               0\n",
      "159               0\n",
      "160               0\n",
      "161               0\n",
      "162               0\n",
      "163               0\n",
      "164               0\n",
      "165               0\n",
      "\n",
      "[166 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the classes\n",
    "\n",
    "PredictionClassResults = pd.DataFrame(classes, columns=['classification'])\n",
    "# PredictionClassResults = pd.DataFrame(classes)\n",
    "\n",
    "print(PredictionClassResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a dataframe with all of the file names in the folder\n",
    "\n",
    "filelist = os.listdir(imagesFolder)\n",
    "\n",
    "# path = os.path.join(os.getcwd(),'C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images/')\n",
    "# files = [os.path.join(path,i) for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the file listing into a dataframe\n",
    "\n",
    "filelisting = pd.DataFrame(filelist, columns=['FileName'])\n",
    "# filelisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_YoYo_g02_c03.avi']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will identify the video in the folder\n",
    "\n",
    "videofilelist = [ f for f in listdir(videoFolder) if isfile(join(videoFolder,f)) ]\n",
    "videofilelist\n",
    "\n",
    "# path = os.path.join(os.getcwd(),videoFolder)\n",
    "#files = [os.path.join(path,i) for i in os.listdir(path) if os.path.isfile(os.path.join(path,i))]\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the video file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults.loc[:, 'VideoName'] = videofilelist\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the image file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults['FileName'] = filelisting['FileName']\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the file names to the main prediction dataframe\n",
    "\n",
    "PredictionResults['classification'] = PredictionClassResults['classification']\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the date to the main prediction dataframe\n",
    "\n",
    "PredictionResults['DateTime'] = dt.datetime.now()\n",
    "# PredictionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the Order of the Dataframe to look nicer.\n",
    "\n",
    "PredictionResults = PredictionResults[['VideoName','FileName','DateTime','HorseRace','HorseRiding','YoYo','classification']]\n",
    "\n",
    "#cols = PredictionResults.columns.tolist()\n",
    "#cols = cols[-1:] + cols[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe into a csv file\n",
    "\n",
    "export_csv = PredictionResults.to_csv(r'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Results/PredictionResults.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and remove old files that will not be used\n",
    "\n",
    "for the_file in os.listdir(imagesFolder):\n",
    "    file_path = os.path.join(imagesFolder, the_file)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single image to test\n",
    "\n",
    "# img = cv2.imread('C:/Users/derek/Documents/Python_Scripts/Project_Adam/New_Video/Images/frame7.jpg') #frame7\n",
    "# img = cv2.resize(img,(horizontal_size,vertical_size))\n",
    "# img = np.reshape(img,[1,horizontal_size,vertical_size,layer_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = model.predict(img)\n",
    "# classes = model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    \"\"\"After predicting on each batch, check that batch's\n",
    "    accuracy to make sure things are good to go. This is\n",
    "    a simple accuracy metric, and so doesn't take confidence\n",
    "    into account, which would be a better metric to use to\n",
    "    compare changes in the model.\"\"\"\n",
    "    correct = 0\n",
    "    for frame in predictions:\n",
    "        # Get the highest confidence class.\n",
    "        this_prediction = frame[0].tolist()\n",
    "        this_label = frame[1]\n",
    "\n",
    "        max_value = max(this_prediction)\n",
    "        max_index = this_prediction.index(max_value)\n",
    "        predicted_label = labels[max_index]\n",
    "\n",
    "        # Now see if it matches.\n",
    "        if predicted_label == this_label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
