{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Video Classification Tutorial - Using CNN + RNN & LSTM\n",
    "# TensorFlow CPU + Keras \n",
    "#########################################################################\n",
    "\n",
    "\n",
    "# GOAL - To understand the actions within a small video file (3-10 sec) \n",
    "# and then make a prediction of this video into various predefined classes. \n",
    "\n",
    "# DETAILS: The classes are embeded directly into the file name \n",
    "# and folder structure and will be substracted.\n",
    "\n",
    "# From what I understand, we will first prepare the CNN by downloading \n",
    "# the Inceptionv3 pretrained algorithm (in TensorFlow and Keras) \n",
    "# and then add our specific video information into the top layer \n",
    "# of Inceptionv3 and retrain just that portion of the neural network.\n",
    "\n",
    "# We will then flatten the results of the CNN and then feed the newly saved \n",
    "# features/weights into a Long Short Term Memory(LSTM) Recurrent Neural \n",
    "# Network (RNN) for further processing.\n",
    "\n",
    "# What this code should do would be to take the video and split it into\n",
    "# individual images via the cv2 package. For ease of use, we grab the 25th \n",
    "# frame of each video and then feed this into the the CNN.\n",
    "\n",
    "# I think that the goal will be to seperate this code into at least 2 files\n",
    "#      1. Training & Testing Procedure\n",
    "#      2. Application of trained algorithm to new video\n",
    "\n",
    "# https://www.analyticsvidhya.com/blog/2018/09/deep-learning-video-classification-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "# Declare Packages\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "print(cv2.__version__)\n",
    "\n",
    "# Initialize Core Packages\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "# new stuff\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data_dir\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "##### Initialize Core Packages\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "# new stuff\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Variables to be used later.\n",
    "\n",
    "algorithmFolder = \"C:/Users/derek/Documents/Python_Scripts/Project_Adam/Model_Training_Routines/Classification/\"\n",
    "Raw_Video_Source = 'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Raw_Video/'\n",
    "Video_Frame_Destination = 'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Raw_Video_Processed/'\n",
    "Training_Sample = 0.95\n",
    "\n",
    "base_dir = 'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Raw_Video_Processed'\n",
    "\n",
    "# This frame extract rate will pick up the Nth frame of a video.\n",
    "\n",
    "frame_extract_rate = 25\n",
    "\n",
    "# The shape of the individual image is 3 layers of 240 pixels by 320 pixels\n",
    "\n",
    "horizontal_size = 240\n",
    "vertical_size = 320\n",
    "layer_count = 3\n",
    "\n",
    "\n",
    "batch_size = 1 # Originally 64. \n",
    "model_batch_size = 64\n",
    "\n",
    "\n",
    "label_count = 3 #Originally 3 - I think this is the # of classes\n",
    "\n",
    "sample_multiple = 1 #This is used for the training procedure. Sample Size * n\n",
    "\n",
    "Epochs_CNN = 10\n",
    "Epochs_LSTM = 30\n",
    "\n",
    "train_data_dir = 'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Raw_Video_Processed/train/'\n",
    "validation_data_dir = 'C:/Users/derek/Documents/Python_Scripts/Project_Adam/Raw_Video_Processed/test/'\n",
    "nb_train_samples = 136  #total\n",
    "nb_validation_samples = 98  # total\n",
    "epochs = 1\n",
    "batch_size = 1\n",
    "\n",
    "# This will place a hard cap of the total number of frames to N within a video clip.\n",
    "\n",
    "video_frame_count = 80\n",
    "\n",
    "# This will be a count of the videos for the RNN training\n",
    "\n",
    "# video_train_count = 10\n",
    "# video_test_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Inception 3 algorithm \n",
    "\n",
    "from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will re-train the top layer of Inception with our own dataset. Thats why we define include_top to false\n",
    "# The shape of the individual image is 3 layers of 240 pixels by 320 pixels\n",
    "\n",
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(horizontal_size, vertical_size, layer_count)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 240, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 119, 159, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 119, 159, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 119, 159, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 117, 157, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 117, 157, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 117, 157, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 117, 157, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 117, 157, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 117, 157, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 58, 78, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 58, 78, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 58, 78, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 58, 78, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 76, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 76, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 76, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 27, 37, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 27, 37, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 27, 37, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 27, 37, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 27, 37, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 27, 37, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 27, 37, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 27, 37, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 27, 37, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 27, 37, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 27, 37, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 27, 37, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 27, 37, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 27, 37, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 27, 37, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 27, 37, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 27, 37, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 27, 37, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 27, 37, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 27, 37, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 27, 37, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 27, 37, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 27, 37, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 27, 37, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 27, 37, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 27, 37, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 27, 37, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 27, 37, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 27, 37, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 27, 37, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 27, 37, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 27, 37, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 27, 37, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 27, 37, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 27, 37, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 27, 37, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 27, 37, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 27, 37, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 27, 37, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 27, 37, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 27, 37, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 27, 37, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 27, 37, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 27, 37, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 27, 37, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 27, 37, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 27, 37, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 27, 37, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 27, 37, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 27, 37, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 27, 37, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 27, 37, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 27, 37, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 27, 37, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 27, 37, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 27, 37, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 27, 37, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 27, 37, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 27, 37, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 27, 37, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 27, 37, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 27, 37, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 27, 37, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 27, 37, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 27, 37, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 27, 37, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 27, 37, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 27, 37, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 27, 37, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 27, 37, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 27, 37, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 27, 37, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 27, 37, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 27, 37, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 27, 37, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 27, 37, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 18, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 13, 18, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 13, 18, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 18, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 13, 18, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 13, 18, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 13, 18, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 13, 18, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 13, 18, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 13, 18, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 13, 18, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 13, 18, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 13, 18, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 13, 18, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 13, 18, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 13, 18, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 13, 18, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 13, 18, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 13, 18, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 13, 18, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 13, 18, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 13, 18, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 13, 18, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 13, 18, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 13, 18, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 13, 18, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 13, 18, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 13, 18, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 13, 18, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 13, 18, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 13, 18, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 13, 18, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 13, 18, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 13, 18, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 13, 18, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 13, 18, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 13, 18, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 13, 18, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 13, 18, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 13, 18, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 18, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 18, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 13, 18, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 13, 18, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 13, 18, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 13, 18, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 13, 18, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 13, 18, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 13, 18, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 13, 18, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 13, 18, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 13, 18, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 13, 18, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 13, 18, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 13, 18, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 18, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 13, 18, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 13, 18, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 13, 18, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 13, 18, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 13, 18, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 13, 18, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 18, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 13, 18, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 13, 18, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 13, 18, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 13, 18, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 13, 18, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 13, 18, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 13, 18, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 13, 18, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 13, 18, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 18, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 13, 18, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 13, 18, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 13, 18, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 13, 18, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 13, 18, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 18, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 13, 18, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 13, 18, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 18, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 13, 18, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 13, 18, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 13, 18, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 13, 18, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 13, 18, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 18, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 13, 18, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 13, 18, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 13, 18, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 13, 18, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 13, 18, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 13, 18, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 13, 18, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 13, 18, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 13, 18, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 18, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 13, 18, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 13, 18, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 13, 18, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 13, 18, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 13, 18, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 13, 18, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 13, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 13, 18, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 13, 18, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 13, 18, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 13, 18, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 13, 18, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 13, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 13, 18, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 13, 18, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 13, 18, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 13, 18, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 13, 18, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 13, 18, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 13, 18, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 13, 18, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 13, 18, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 13, 18, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 13, 18, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 13, 18, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 13, 18, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 13, 18, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 13, 18, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 13, 18, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 13, 18, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 13, 18, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 13, 18, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 13, 18, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 13, 18, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 13, 18, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 13, 18, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 13, 18, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 13, 18, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 13, 18, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 13, 18, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 18, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 13, 18, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 13, 18, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 18, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 13, 18, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 13, 18, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 13, 18, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 13, 18, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 18, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 18, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 6, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 6, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 6, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 6, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 6, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 6, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 6, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 6, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 6, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 6, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 6, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 6, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 6, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 6, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 6, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 6, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 6, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 6, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 6, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 6, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 6, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 6, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 6, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 6, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 6, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 6, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 6, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 6, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 6, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 6, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 6, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 6, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 6, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 6, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 6, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 6, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 6, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 6, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 6, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 6, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 6, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 6, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 6, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 6, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 6, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 6, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 6, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 6, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 6, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 6, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 6, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 6, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 6, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Review the output parameters for the Inception v3\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (layer_count, horizontal_size, vertical_size)\n",
    "else:\n",
    "    input_shape = (horizontal_size, vertical_size, layer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that identifies all of the videos in a directory and creates a proper training and testing split.\n",
    "\n",
    "def videos2frames(source_dir, target_dir, train_percentage):\n",
    "    import os\n",
    "    import re\n",
    "    \n",
    "    delete_dir(target_dir)\n",
    "    create_dir_if_not_exists(target_dir)\n",
    "    \n",
    "    data_dirs = (f for f in sorted(os.listdir(source_dir)) if not f.startswith('.'))\n",
    "                \n",
    "    for cat_name in data_dirs:\n",
    "        source_cat_dir = os.path.join(source_dir, cat_name)\n",
    "        groups = list({re.search('^\\w+_\\w+_g(\\d\\d)_c(\\d\\d)', f).group(1) for f in os.listdir(source_cat_dir) if not f.startswith('.')})\n",
    "        group_size = len(groups)\n",
    "        np.random.shuffle(groups)\n",
    "                 \n",
    "        x = 0\n",
    "        y = 0\n",
    "        \n",
    "        video_dir = os.path.join(source_dir, cat_name)\n",
    "        \n",
    "        video_path = (f for f in os.listdir(video_dir) if not f.startswith('.'))\n",
    "        for video_file in video_path:\n",
    "            m = re.search('^\\w+_\\w+_g(\\d\\d)_c(\\d\\d)', video_file)\n",
    "            group_name = m.group(1)\n",
    "            subject_name = m.group(2)\n",
    "                 \n",
    "            if group_name in groups[:int(group_size * train_percentage)]:\n",
    "                parent_dir = 'train'\n",
    "                x += 1\n",
    "            else:\n",
    "                parent_dir = 'test'\n",
    "                y += 1\n",
    "                 \n",
    "            src_video_path = os.path.join(video_dir, video_file)\n",
    "            frames_dir = os.path.join(os.path.join(target_dir, parent_dir),cat_name)\n",
    "                 \n",
    "            create_dir_if_not_exists(frames_dir)\n",
    "            extract_frames_from_video(src_video_path, frames_dir, \"{}-{}\".format(group_name, subject_name))\n",
    "                \n",
    "def create_dir_if_not_exists(path):\n",
    "    import os\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "                        \n",
    "def delete_dir(path):\n",
    "    import shutil\n",
    "    import os\n",
    "                 \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that extracts the frames from a video.\n",
    "\n",
    "def extract_frames_from_video(video_path, target_dir, target_file_prefix):\n",
    "    import cv2\n",
    "    \n",
    "    v = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    success, image = v.read()\n",
    "    count = 0 \n",
    "    \n",
    "    while success:\n",
    "        count += 1\n",
    "        if count % frame_extract_rate == 0:\n",
    "            cv2.imwrite('{}/{}-{}.jpg'.format(target_dir, target_file_prefix, count), image)\n",
    "        success, image = v.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the funciton which creates the training/test split and also extracts out individual pictures\n",
    "\n",
    "videos2frames(Raw_Video_Source, Video_Frame_Destination, Training_Sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and validation directories for later.\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a count of the total number of features\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 6, 8, 2048))\n",
    "    labels = np.zeros(shape=(sample_count, label_count)) \n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(horizontal_size, vertical_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        print(i * batch_size)\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels \n",
    "\n",
    "#         if i * batch_size >= sample_count:\n",
    "#             batch_size = sample_count-(i * batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "generator = datagen.flow_from_directory(validation_dir, \n",
    "                                        target_size=(horizontal_size, vertical_size), \n",
    "                                        batch_size=batch_size, \n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls out programatically the total number of images to be used at a later time.\n",
    "prev_cell_output = str(output)\n",
    "\n",
    "# This finds the nth word of a string\n",
    "image_number = int(prev_cell_output.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make the batch size equal\n",
    " \n",
    "batch_size_validate = image_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 229 images belonging to 3 classes.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n"
     ]
    }
   ],
   "source": [
    "# This will run the validation routine and begin to train the features. Sample size is a multiple of the batch\n",
    "\n",
    "validation_features, validation_labels = extract_features(validation_dir, batch_size_validate*sample_multiple) # Original 237, batch size times 2 ensures no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229, 6, 8, 2048), (229, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will save the validation routine's features and labels.\n",
    "\n",
    "np.save(\"validation_features.npy\", validation_features)\n",
    "np.save(\"validation_labels.npy\", validation_labels)\n",
    "\n",
    "validation_features.shape, validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output2\n",
    "\n",
    "generator_train = datagen.flow_from_directory(train_dir, \n",
    "                                              target_size=(horizontal_size, vertical_size), \n",
    "                                              batch_size=batch_size, \n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls out programatically the total number of images to be used at a later time.\n",
    "prev_cell_output2 = str(output2)\n",
    "\n",
    "# This finds the nth word of a string\n",
    "image_number2 = int(prev_cell_output2.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we will export the # of images above  to a dynamic value\n",
    "\n",
    "batch_size_train = image_number2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2980 images belonging to 3 classes.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n"
     ]
    }
   ],
   "source": [
    "# This will run the training routine and begin to train the features. Sample size is a multiple of the batch\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, batch_size_train*sample_multiple) # Original 3104, batch size times 2 ensures no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2980, 6, 8, 2048), (2980, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will save the training routine's features and labels.\n",
    "\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_labels)\n",
    "\n",
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of the train features and validation features \n",
    "\n",
    "train_features = np.reshape(train_features, (batch_size_train*sample_multiple, 6 * 8 * 2048)) # Original 3104 \n",
    "validation_features = np.reshape(validation_features, (batch_size_validate*sample_multiple, 6 * 8 * 2048)) # Original 237\n",
    "\n",
    "# train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(batch_size_train, 6*8*2048)      # converting to 1-D, 375 is image_number2\n",
    "validation_features = validation_features.reshape(batch_size_validate, 6*8*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new simple CNN model and add layers based upon features substracted from existing Inception model\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=6 * 8 * 2048)) # input_dim=6 * 8 * 2048) input_shape\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(label_count, activation='softmax'))\n",
    "\n",
    "\n",
    "# This is the top layer. Dense 3 represents the 3 classes we are trying to predict.\n",
    "\n",
    "# model.add(Dense(3)) \n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=2e-6),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2980 samples, validate on 229 samples\n",
      "Epoch 1/10\n",
      "2980/2980 [==============================] - 35s 12ms/step - loss: 0.7625 - acc: 0.6812 - val_loss: 0.1852 - val_acc: 0.9520\n",
      "Epoch 2/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.2216 - acc: 0.9275 - val_loss: 0.1073 - val_acc: 0.9738\n",
      "Epoch 3/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.1350 - acc: 0.9594 - val_loss: 0.0717 - val_acc: 0.9869\n",
      "Epoch 4/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.0930 - acc: 0.9718 - val_loss: 0.0697 - val_acc: 0.9825\n",
      "Epoch 5/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.0712 - acc: 0.9779 - val_loss: 0.0554 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.0559 - acc: 0.9849 - val_loss: 0.0517 - val_acc: 0.9869\n",
      "Epoch 7/10\n",
      "2980/2980 [==============================] - 31s 10ms/step - loss: 0.0417 - acc: 0.9889 - val_loss: 0.0487 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "2980/2980 [==============================] - 30s 10ms/step - loss: 0.0352 - acc: 0.9923 - val_loss: 0.0466 - val_acc: 0.9869\n",
      "Epoch 9/10\n",
      "2980/2980 [==============================] - 29s 10ms/step - loss: 0.0313 - acc: 0.9919 - val_loss: 0.0437 - val_acc: 0.9869\n",
      "Epoch 10/10\n",
      "2980/2980 [==============================] - 29s 10ms/step - loss: 0.0219 - acc: 0.9970 - val_loss: 0.0432 - val_acc: 0.9869\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs=Epochs_CNN, #Original 10\n",
    "                   batch_size=model_batch_size, #Original 64\n",
    "                   validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               25166080  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 25,166,851\n",
      "Trainable params: 25,166,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt4VOW5/vHvQwDDGUWsSoCgssWAAWJE/KEGD3WDVlBrFYQqFkWttLa2e0vVWqRl1ypViuXnlh6sW6LItlXRovQgitqKhKMCUigiRBADFZSTEHj2H2sSJmGSrCSTTLJyf65rrsxa886aJxO4Z8273vUuc3dERCRamqW6ABERST6Fu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRJDCXRIyszQz22Vm3ZLZNpXM7BQzS/rYXzO7yMw2xC2vMbNzw7StwWv92szuqunzK9nuT8zsd8nerqRO81QXIMlhZrviFlsDXwAHY8s3u3t+dbbn7geBtslu2xS4+6nJ2I6Z3QiMdvfBcdu+MRnbluhTuEeEu5eGa2zP8EZ3/0tF7c2subsX10dtIlL/1C3TRMS+dj9jZk+b2efAaDM728zeNrMdZrbFzKaZWYtY++Zm5maWGVueGXv8ZTP73Mz+bmY9qts29vhQM/uHme00s0fM7C0zG1NB3WFqvNnM1pnZp2Y2Le65aWb2sJltN7N/AkMqeX/uMbNZ5dZNN7OHYvdvNLPVsd/nn7G96oq2VWhmg2P3W5vZk7HaVgJnJHjd9bHtrjSzYbH1pwO/BM6NdXlti3tvJ8Y9/5bY777dzJ43sxPCvDdVMbPLY/XsMLNXzezUuMfuMrPNZvaZmb0f97sONLMlsfVbzezBsK8ndcDddYvYDdgAXFRu3U+A/cBlBB/qrYAzgbMIvsGdBPwDGB9r3xxwIDO2PBPYBuQCLYBngJk1aHsc8DkwPPbYHcABYEwFv0uYGl8AOgCZwL9KfndgPLASyAA6AQuCf/IJX+ckYBfQJm7bnwC5seXLYm0MuADYC2THHrsI2BC3rUJgcOz+FOA14GigO7CqXNurgRNif5NrYzV8KfbYjcBr5eqcCUyM3b84VmM/IB34/8CrYd6bBL//T4Dfxe6fFqvjgtjf6K7Y+94C6A18CBwfa9sDOCl2fxEwMna/HXBWqv8vNOWb9tybljfd/UV3P+Tue919kbsvdPdid18PzADyKnn+s+5e4O4HgHyCUKlu268Ay9z9hdhjDxN8ECQUssafuvtOd99AEKQlr3U18LC7F7r7duD+Sl5nPfAewYcOwJeBHe5eEHv8RXdf74FXgb8CCQ+alnM18BN3/9TdPyTYG49/3dnuviX2N3mK4IM5N8R2AUYBv3b3Ze6+D5gA5JlZRlybit6byowA5rj7q7G/0f1Ae4IP2WKCD5Lesa69D2LvHQQf0j3NrJO7f+7uC0P+HlIHFO5Ny6b4BTPrZWZ/NLOPzewzYBJwbCXP/zju/h4qP4haUdsT4+twdyfY000oZI2hXotgj7MyTwEjY/evJfhQKqnjK2a20Mz+ZWY7CPaaK3uvSpxQWQ1mNsbMlse6P3YAvUJuF4Lfr3R77v4Z8CnQJa5Ndf5mFW33EMHfqIu7rwG+R/B3+CTWzXd8rOkNQBawxszeMbNLQv4eUgcU7k1L+WGAjxHsrZ7i7u2Bewm6HerSFoJuEgDMzCgbRuXVpsYtQNe45aqGaj4DXBTb8x1OEPaYWSvgWeCnBF0mHYE/hazj44pqMLOTgEeBW4FOse2+H7fdqoZtbibo6inZXjuC7p+PQtRVne02I/ibfQTg7jPdfRBBl0wawfuCu69x9xEEXW8/B35vZum1rEVqSOHetLUDdgK7zew04OZ6eM2XgBwzu8zMmgO3A53rqMbZwHfMrIuZdQLurKyxu28F3gQeB9a4+9rYQ0cBLYEi4KCZfQW4sBo13GVmHS04D2B83GNtCQK8iOBz7kaCPfcSW4GMkgPICTwNjDWzbDM7iiBk33D3Cr8JVaPmYWY2OPba/0FwnGShmZ1mZufHXm9v7HaQ4Bf4upkdG9vT3xn73Q7VshapIYV70/Y94HqC/7iPEey51qlYgF4DPARsB04GlhKMy092jY8S9I2/S3Cw79kQz3mK4ADpU3E17wC+CzxHcFDyKoIPqTB+RPANYgPwMvA/cdtdAUwD3om16QXE91P/GVgLbDWz+O6Vkue/QtA98lzs+d0I+uFrxd1XErznjxJ88AwBhsX6348CHiA4TvIxwTeFe2JPvQRYbcForCnANe6+v7b1SM1Y0OUpkhpmlkbQDXCVu7+R6npEokJ77lLvzGyImXWIfbX/IcEIjHdSXJZIpIQK99h/xjWxkyEmJHi8m5nNN7OlZrZCR8mlCucA6wm+2g8BLnf3irplRKQGquyWiX1t/gfBuN9CDp+osCquzQxgqbs/amZZwFx3z6yzqkVEpFJh9twHAOtiJ3DsB2Zx+ESPEk5wkgMEZ8NtTl6JIiJSXWEmDutC2ZMwCgnOVIs3EfiTmX0LaEMw2uAIZjYOGAfQpk2bM3r16pWomYiIVGDx4sXb3L2y4cNAuHBPdKJG+b6ckQTzUvzczM4GnjSzPrHxroef5D6D4PRxcnNzvaCgIMTLi4hICTOr6kxrIFy3TCFlz7DL4Mhul7EEJz7g7n8nmHsi7CnUIiKSZGHCfRHBZEA9zKwlsUmFyrXZSOyMvdhZhOkEJz+IiEgKVBnuHlzQYTwwD1gNzHb3lWY2qWTuaYKzCG8ys+UEp0SPcZ0dJSKSMqGuxOTuc4G55dbdG3d/FTAouaWJSDIdOHCAwsJC9u3bl+pSJIT09HQyMjJo0aKiqYUqp8vsiTQRhYWFtGvXjszMTILJOKWhcne2b99OYWEhPXr0qPoJCTSq6Qfy8yEzE5o1C37mV+uSzyJN2759++jUqZOCvREwMzp16lSrb1mNZs89Px/GjYM9e4LlDz8MlgFG1XoePJGmQcHeeNT2b9Vo9tzvvvtwsJfYsydYLyIiZTWacN+4sXrrRaRh2b59O/369aNfv34cf/zxdOnSpXR5//5w077fcMMNrFmzptI206dPJz9JfbbnnHMOy5YtS8q26luj6Zbp1i3oikm0XkSSLz8/+Ga8cWPw/2zy5Np1gXbq1Kk0KCdOnEjbtm35/ve/X6aNu+PuNGuWeL/z8ccfr/J1brvttpoXGSGNZs998mRo3brsutatg/Uiklwlx7g+/BDcDx/jqotBDOvWraNPnz7ccsst5OTksGXLFsaNG0dubi69e/dm0qRJpW1L9qSLi4vp2LEjEyZMoG/fvpx99tl88sknANxzzz1MnTq1tP2ECRMYMGAAp556Kn/7298A2L17N1/96lfp27cvI0eOJDc3t8o99JkzZ3L66afTp08f7rrrLgCKi4v5+te/Xrp+2rRpADz88MNkZWXRt29fRo8enfT3LIxGE+6jRsGMGdC9O5gFP2fM0MFUkbpQ38e4Vq1axdixY1m6dCldunTh/vvvp6CggOXLl/PnP/+ZVatWHfGcnTt3kpeXx/Llyzn77LP57W9/m3Db7s4777zDgw8+WPpB8cgjj3D88cezfPlyJkyYwNKlSyutr7CwkHvuuYf58+ezdOlS3nrrLV566SUWL17Mtm3bePfdd3nvvfe47rrrAHjggQdYtmwZy5cv55e//GUt352aaTThDkGQb9gAhw4FPxXsInWjvo9xnXzyyZx55pmly08//TQ5OTnk5OSwevXqhOHeqlUrhg4dCsAZZ5zBhg0bEm77yiuvPKLNm2++yYgRIwDo27cvvXv3rrS+hQsXcsEFF3DsscfSokULrr32WhYsWMApp5zCmjVruP3225k3bx4dOnQAoHfv3owePZr8/Pwan4RUW40q3EWkflR0LKuujnG1adOm9P7atWv5xS9+wauvvsqKFSsYMmRIwvHeLVu2LL2flpZGcXFxwm0fddRRR7Sp7uwoFbXv1KkTK1as4JxzzmHatGncfPPNAMybN49bbrmFd955h9zcXA4ePFit10sGhbuIHCGVx7g+++wz2rVrR/v27dmyZQvz5s1L+mucc845zJ49G4B333034TeDeAMHDmT+/Pls376d4uJiZs2aRV5eHkVFRbg7X/va17jvvvtYsmQJBw8epLCwkAsuuIAHH3yQoqIi9pTv46oHjWa0jIjUn5Iuz2SOlgkrJyeHrKws+vTpw0knncSgQcmftupb3/oW1113HdnZ2eTk5NCnT5/SLpVEMjIymDRpEoMHD8bdueyyy7j00ktZsmQJY8eOxd0xM372s59RXFzMtddey+eff86hQ4e48847adeuXdJ/h6pUeQ3VuqKLdYjUr9WrV3PaaaeluowGobi4mOLiYtLT01m7di0XX3wxa9eupXnzhrW/m+hvZmaL3T23quc2rN9ERKQe7Nq1iwsvvJDi4mLcnccee6zBBXttReu3EREJoWPHjixevDjVZdQpHVAVEYkghbuISAQp3EVEIihUuJvZEDNbY2brzGxCgscfNrNlsds/zGxH8ksVEZGwqgx3M0sDpgNDgSxgpJllxbdx9++6ez937wc8AvyhLooVkcZr8ODBR5yQNHXqVL75zW9W+ry2bdsCsHnzZq666qoKt13V0OqpU6eWOZnokksuYceO2u+HTpw4kSlTptR6O8kWZs99ALDO3de7+35gFjC8kvYjgaeTUZyIRMfIkSOZNWtWmXWzZs1i5MiRoZ5/4okn8uyzz9b49cuH+9y5c+nYsWONt9fQhQn3LsCmuOXC2LojmFl3oAfwagWPjzOzAjMrKCoqqm6tItKIXXXVVbz00kt88cUXAGzYsIHNmzdzzjnnlI47z8nJ4fTTT+eFF1444vkbNmygT58+AOzdu5cRI0aQnZ3NNddcw969e0vb3XrrraXTBf/oRz8CYNq0aWzevJnzzz+f888/H4DMzEy2bdsGwEMPPUSfPn3o06dP6XTBGzZs4LTTTuOmm26id+/eXHzxxWVeJ5Fly5YxcOBAsrOzueKKK/j0009LXz8rK4vs7OzSCctef/310ouV9O/fn88//7zG720iYca5J7qQX0WntY4AnnX3hLPkuPsMYAYEZ6iGqlBEku4734FkX2CoXz+I5WJCnTp1YsCAAbzyyisMHz6cWbNmcc0112BmpKen89xzz9G+fXu2bdvGwIEDGTZsWIXXEX300Udp3bo1K1asYMWKFeTk5JQ+NnnyZI455hgOHjzIhRdeyIoVK/j2t7/NQw89xPz58zn22GPLbGvx4sU8/vjjLFy4EHfnrLPOIi8vj6OPPpq1a9fy9NNP86tf/Yqrr76a3//+95XOz37dddfxyCOPkJeXx7333st9993H1KlTuf/++/nggw846qijSruCpkyZwvTp0xk0aBC7du0iPT29Gu921cLsuRcCXeOWM4DNFbQdgbpkRKQC8V0z8V0y7s5dd91FdnY2F110ER999BFbt26tcDsLFiwoDdns7Gyys7NLH5s9ezY5OTn079+flStXVjkp2JtvvskVV1xBmzZtaNu2LVdeeSVvvPEGAD169KBfv35A5dMKQzC//I4dO8jLywPg+uuvZ8GCBaU1jho1ipkzZ5aeCTto0CDuuOMOpk2bxo4dO5J+hmyYrS0CeppZD+AjggC/tnwjMzsVOBr4e1IrFJGkq2wPuy5dfvnl3HHHHSxZsoS9e/eW7nHn5+dTVFTE4sWLadGiBZmZmQmn+Y2XaK/+gw8+YMqUKSxatIijjz6aMWPGVLmdyubXKpkuGIIpg6vqlqnIH//4RxYsWMCcOXP48Y9/zMqVK5kwYQKXXnopc+fOZeDAgfzlL3+hV69eNdp+IlXuubt7MTAemAesBma7+0ozm2Rmw+KajgRmeapmIhORBq9t27YMHjyYb3zjG2UOpO7cuZPjjjuOFi1aMH/+fD5MdMHkOOedd17pRbDfe+89VqxYAQTTBbdp04YOHTqwdetWXn755dLntGvXLmG/9nnnncfzzz/Pnj172L17N8899xznnntutX+3Dh06cPTRR5fu9T/55JPk5eVx6NAhNm3axPnnn88DDzzAjh072LVrF//85z85/fTTufPOO8nNzeX999+v9mtWJtT3AHefC8wtt+7ecssTk1eWiETVyJEjufLKK8uMnBk1ahSXXXYZubm59OvXr8o92FtvvZUbbriB7Oxs+vXrx4ABA4Dgqkr9+/end+/eR0wXPG7cOIYOHcoJJ5zA/PnzS9fn5OQwZsyY0m3ceOON9O/fv9IumIo88cQT3HLLLezZs4eTTjqJxx9/nIMHDzJ69Gh27tyJu/Pd736Xjh078sMf/pD58+eTlpZGVlZW6VWlkkVT/oo0EZryt/GpzZS/mn5ARCSCFO4iIhGkcBdpQjTeofGo7d9K4S7SRKSnp7N9+3YFfCPg7mzfvr1WJzbpSkwiTURGRgaFhYVo6o/GIT09nYyMjBo/X+Eu0kS0aNGCHj16pLoMqSfqlhERiSCFu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRJDCXUQkghTuIiIRpHAXEYkghbuISASFCnczG2Jma8xsnZlNqKDN1Wa2ysxWmtlTyS1TRESqo8q5ZcwsDZgOfBkoBBaZ2Rx3XxXXpifwA2CQu39qZsfVVcEiIlK1MHvuA4B17r7e3fcDs4Dh5drcBEx3908B3P2T5JYpIiLVESbcuwCb4pYLY+vi/Rvwb2b2lpm9bWZDklWgiIhUX5gpfy3BuvKz/TcHegKDgQzgDTPr4+47ymzIbBwwDqBbt27VLlZERMIJs+deCHSNW84ANido84K7H3D3D4A1BGFfhrvPcPdcd8/t3LlzTWsWEZEqhAn3RUBPM+thZi2BEcCccm2eB84HMLNjCbpp1iezUBERCa/KcHf3YmA8MA9YDcx295VmNsnMhsWazQO2m9kqYD7wH+6+va6KFhGRylmqLpabm5vrBQUFKXltEZHGyswWu3tuVe10hqqISAQp3EVEIkjhLiISQQp3EZEIUriLiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO4iIhGkcBcRiSCFu4hIBCncRUQiKFS4m9kQM1tjZuvMbEKCx8eYWZGZLYvdbkx+qSIiElbzqhqYWRowHfgyUAgsMrM57r6qXNNn3H18HdQoIiLVFGbPfQCwzt3Xu/t+YBYwvG7LEhGR2ggT7l2ATXHLhbF15X3VzFaY2bNm1jXRhsxsnJkVmFlBUVFRDcoVEZEwwoS7JVjn5ZZfBDLdPRv4C/BEog25+wx3z3X33M6dO1evUhERCS1MuBcC8XviGcDm+Abuvt3dv4gt/go4IznliYhITYQJ90VATzPrYWYtgRHAnPgGZnZC3OIwYHXyShQRkeqqcrSMuxeb2XhgHpAG/NbdV5rZJKDA3ecA3zazYUAx8C9gTB3WLCIiVTD38t3n9SM3N9cLCgpS8toiIo2VmS1299yq2ukMVRGRCFK4i4hEkMJdRCSCFO4iIhGkcBcRiSCFu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRJDCXUQkghTuIiIRpHAXEYkghbuISAQp3EVEIkjhLiISQQp3EZEIUriLiERQqHA3syFmtsbM1pnZhEraXWVmbmZVXgJKRETqTpXhbmZpwHRgKJAFjDSzrATt2gHfBhYmu0gREameMHvuA4B17r7e3fcDs4DhCdr9GHgA2JfE+kREpAbChHsXYFPccmFsXSkz6w90dfeXKtuQmY0zswIzKygqKqp2sSIiEk6YcLcE67z0QbNmwMPA96rakLvPcPdcd8/t3Llz+CpFRKRawoR7IdA1bjkD2By33A7oA7xmZhuAgcAcHVQVEUmdMOG+COhpZj3MrCUwAphT8qC773T3Y909090zgbeBYe5eUCcVi4hIlaoMd3cvBsYD84DVwGx3X2lmk8xsWF0XKCIi1dc8TCN3nwvMLbfu3graDq59WSIiUhs6Q1VEJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO4iIhGkcBcRiSCFu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRJDCXUQkghTuIiIRFCrczWyIma0xs3VmNiHB47eY2btmtszM3jSzrOSXKiIiYVUZ7maWBkwHhgJZwMgE4f2Uu5/u7v2AB4CHkl6piIiEFmbPfQCwzt3Xu/t+YBYwPL6Bu38Wt9gG8OSVKCIi1dU8RJsuwKa45ULgrPKNzOw24A6gJXBBog2Z2ThgHEC3bt2qW6uIiIQUZs/dEqw7Ys/c3ae7+8nAncA9iTbk7jPcPdfdczt37ly9SkVEJLQw4V4IdI1bzgA2V9J+FnB5bYoSEZHaCRPui4CeZtbDzFoCI4A58Q3MrGfc4qXA2uSVKCIi1VVln7u7F5vZeGAekAb81t1XmtkkoMDd5wDjzewi4ADwKXB9XRYtIiKVC3NAFXefC8wtt+7euPu3J7kuERGpBZ2hKiISQQp3EZEIUriLiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO41kJ8PmZnQrFnwMz8/1RWJiJQValZIOSw/H8aNgz17guUPPwyWAUaNSl1dIiLxtOdeTXfffTjYS+zZE6wXEWkoFO7VtHFj9daLiKSCwr2aunWr3noRkVQIFe5mNsTM1pjZOjObkODxO8xslZmtMLO/mln35JfaMEyeDK1bl13XunWwXkSkoagy3M0sDZgODAWygJFmllWu2VIg192zgWeBB5JdaEMxahTMmAHdu4NZ8HPGDB1MFZGGJcxomQHAOndfD2Bms4DhwKqSBu4+P67928DoZBbZ0IwapTAXkYYtTLdMF2BT3HJhbF1FxgIvJ3rAzMaZWYGZFRQVFYWvUkREqiVMuFuCdZ6wodloIBd4MNHj7j7D3XPdPbdz587hqxQRkWoJ0y1TCHSNW84ANpdvZGYXAXcDee7+RXLKExGRmgiz574I6GlmPcysJTACmBPfwMz6A48Bw9z9k+SXedgHH8DDD0NxcV2+iohI41ZluLt7MTAemAesBma7+0ozm2Rmw2LNHgTaAv9rZsvMbE4Fm6u1mTPhjjsgNxfefruuXkVEpHEz94Td53UuNzfXCwoKqv08d/jDH+D222HzZrjpJvjpT+GYY+qgSBGRBsbMFrt7blXtGt0Zqmbw1a/C6tXwne/Ab34DvXrB//xPEPwiItIIw71Eu3bw0ENQUAAnnwzXXw/nnx+EvohIU9dow71Ev37w1lvw2GOwYgX07Qt33XXkzI0iIk1Jow93CC6aMW4cvP8+jBwZ9MH37g1//GOqKxMRSY1IhHuJ446DJ56A116DVq3gK1+BK6+ETZuqfKqISKREKtxL5OXBsmXwX/8Fr7wCp50GP/85HDiQ6spEROpHJMMdoGVL+MEPYOVKGDwYvv99OOMM+NvfUl2ZiEjdi2y4l+jRA158MRgb/+mnMGhQMDZ++/ZUVyYiUnciH+4QjI2/4opgmOT3vgePPx6Mjf/d7zQ2XkSiqUmEe4m2bWHKFFiyBHr2hBtuCPrnV65MdWU1k58PmZnBaKHMzGBZRASaWLiXyM6GN9+EX/0qCPZ+/WDCBNi9O9WVhZefHwz//PDD4NvHhx8Gywp4EYEmGu4Q7O3eeGMwNn70aPjZz4Kx8S++mOrKwrn77iNP1NqzJ1gvItJkw71E585BH/zrr0ObNjBsGFx+OWzcmOrKKldRfQ29bhGpH00+3Eucdx4sXQr33w9/+lMwNv7BBxvu2Phu3aq3XkSaFoV7nJYt4c47YdUquPBC+M//hJycoH++oZk8GVq3LruudetgvYiIwj2BzEyYMweefx527oRzz4WxY2HbtlRXdtioUTBjBnTvHgz17N49WB41KtWViUhD0Ogu1lHfdu2CSZOCS/t16AAPPABjxgQHZEVE6ltkL9ZR39q2DQJ9yZLgxKexY4P++XffTXVlIiIVCxXuZjbEzNaY2Tozm5Dg8fPMbImZFZvZVckvM/VOPx0WLAiu/PT++9C/P9x8M7z8suaOF5GGp8pwN7M0YDowFMgCRppZVrlmG4ExwFPJLrAhadYMvvGNINxvuCG4tN8llwTXb/33fw+6blav1pQGIpJ6YfbcBwDr3H29u+8HZgHD4xu4+wZ3XwEcqoMaG5xjjw3Obv3Xv4IphW+9NRhffscdkJUVTFZ2yy3BAdnPPkt1tXVP0yCINDxhwr0LEH+5i8LYumozs3FmVmBmBUVFRTXZRIPSqlXZPfYPPoD//u+gyyY/P5isrFOnYMrh+++H5cujt1evaRBEGqYw4W4J1tUootx9hrvnuntu586da7KJBi0zM+iHf+65YErh114LZqHcsSOYW75fPzjxxKBL55lngj3/xk7TIIg0TM1DtCkEusYtZwCb66ac6GjZMphxMi8v2GvfvDk48/WVV+CFF4Lphps1gwEDYMgQGDo0uJhIWlqqK68eTYMg0jCF2XNfBPQ0sx5m1hIYAcyp27Ki58QTg/Hxs2ZBURH8/e/wwx/CoUNw331w1lnwpS/BtdcGB2q3bk11xeFoGgSRhqnKcHf3YmA8MA9YDcx295VmNsnMhgGY2ZlmVgh8DXjMzBrpDOn1Iy0NBg6EiRNh4UL45BN46im49FL461/h+uvh+OODqQ/uvhveeKPhznGjaRBEGiadodrAHDoUHHh95ZXg9tZbcPAgtG8PF10UdOEMGQJdu1a9rfqSnx98CG3cGOyxT56cmmkQGkodInUp7BmqCvcGbufOYG++JOw3xcYtZWUd7qvv1QuaN098S0sL5p6JupJRO/EHd1u31nw7Ej0K9whyD4ZclgT966/D/v1VPy8treLwT9atRYtg/H/XrmVv7dvXz4dLZmYwDLO87t1hw4a6f32R+qJwbwJ27w6mRPjoIygurtvbgQOVP75/fzC081C509jatj0y8DMyyi63bVv796JZs8TnEJgdWZNIYxY23MMMhZQGqk2boFumoThwALZsCbqOCguDnyW3wkJYsQI+/vjI53XseGTgl/+5nxhtAAAGJUlEQVQQaNWq8tfu1i3xnnt9j9pRv780FAp3SZoWLYJAqyxQ9+8PvmlU9AFQUBAMFS2vU6fEe/0l6yZOhNtuO7LPvT5H7ZTv9y85WxcU8FL/1C0jDc6+fYeDP9EHwKZNic/ubd8+eO7+/ZCeHlwq8eST4aijguWKflb2WGVtmzcvezxB/f5SH9QtI41Wejqcckpwq8ju3Yk/ADZvDvac9+2DL74ILpn4xRfBcsm6ffuC4wS1ZVY27BN1OUEQ+MOHB+1atgx3S0bbFi2axkgpSUzhLo1SmzZw6qnBrSYOHgyCPlHwV/Szqseeeir40CmvZcsg4Pfvr/hWlyepmQUfAK1ahRv1VN1RUmHbJeODrGVLXQUtLIW7NElpaUGffPmza2sjL6/mY+3dg4BPFPxffFH5B0P529tvw//+7+EPDPfgm8qZZwbfhsKMfioZAbVnT81GUR08mLz3tby0tOp9GMTf4s/7MKv+rSbPS/Scyy8PphypSwp3kSQpCfCajJYxOxxAtfXznx/5TaC4GNasgXnzar/9MNzhySeD6xrs3Xt4fXo6/OQnwSiv6nxg1fS2a1fwc+vWoNusuDj4JnHMMcG3P/fwt5LfKxnP6dGj7sNdB1RFIqahjPlvKAeYo3b2si6QLdJENZSZOhvKdNBN9ZoDCneRiGkoM3XqQ+ZI9XlJSoW7SMSMGhV0OXTvHnTFdO+emi4IfciUVd+XpFS4i0TQqFFBv/ahQ8HPVPQt60OmrPruHtIBVRGJvIYw50+yDnTrDFURkZhRo1I/Mqa+J7dTt4yISD2o7+6hUOFuZkPMbI2ZrTOzCQkeP8rMnok9vtDMMpNdqIhIY1bfxyCq7JYxszRgOvBloBBYZGZz3H1VXLOxwKfufoqZjQB+BlxTFwWLiDRW9dk9FGbPfQCwzt3Xu/t+YBYwvFyb4cATsfvPAheaaT46EZFUCRPuXYBNccuFsXUJ27h7MbAT6FR+Q2Y2zswKzKygKNEVGUREJCnChHuiPfDyA3rCtMHdZ7h7rrvndu7cOUx9IiJSA2HCvRDoGrecAWyuqI2ZNQc6AAmulSMiIvUhTLgvAnqaWQ8zawmMAOaUazMHuD52/yrgVU/V2VEiIhLuDFUzuwSYCqQBv3X3yWY2CShw9zlmlg48CfQn2GMf4e7rq9hmEZBgSH8oxwLbavjcKNL7UZbej8P0XpQVhfeju7tX2a+dsukHasPMCsKcfttU6P0oS+/HYXovympK74fOUBURiSCFu4hIBDXWcJ+R6gIaGL0fZen9OEzvRVlN5v1olH3uIiJSuca65y4iIpVQuIuIRFCjC/eqph9uKsysq5nNN7PVZrbSzG5PdU0NgZmlmdlSM3sp1bWkmpl1NLNnzez92L+Ts1NdU6qY2Xdj/0/eM7OnY+fmRFqjCve46YeHAlnASDPLSm1VKVMMfM/dTwMGArc14fci3u3A6lQX0UD8AnjF3XsBfWmi74uZdQG+DeS6ex+CkzFHpLaquteowp1w0w83Ce6+xd2XxO5/TvAft/xsnU2KmWUAlwK/TnUtqWZm7YHzgN8AuPt+d9+R2qpSqjnQKjb3VWuOnB8rchpbuIeZfrjJiV35qj+wMLWVpNxU4D+BalxuOLJOAoqAx2PdVL82szapLioV3P0jYAqwEdgC7HT3P6W2qrrX2MI91NTCTYmZtQV+D3zH3T9LdT2pYmZfAT5x98WprqWBaA7kAI+6e39gN9Akj1GZ2dEE3/B7ACcCbcxsdGqrqnuNLdzDTD/cZJhZC4Jgz3f3P6S6nhQbBAwzsw0E3XUXmNnM1JaUUoVAobuXfJt7liDsm6KLgA/cvcjdDwB/AP5fimuqc40t3MNMP9wkxC5j+Btgtbs/lOp6Us3df+DuGe6eSfDv4lV3j/zeWUXc/WNgk5mdGlt1IbCqkqdE2UZgoJm1jv2/uZAmcHC5ygtkNyTuXmxm44F5HJ5+eGWKy0qVQcDXgXfNbFls3V3uPjeFNUnD8i0gP7YjtB64IcX1pIS7LzSzZ4ElBKPMltIEpiHQ9AMiIhHU2LplREQkBIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSC/g95/iX2BYM7KwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostic plots for the CNN algorithm accuracy\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Newly Trained Inception Model\n",
    "\n",
    "model.save(algorithmFolder + 'modeltestDK.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a graph of the inception network\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(conv_base, show_shapes=True, to_file=algorithmFolder + 'ModelGraphic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Phase II - Extract the dense layer from the first trained network \n",
    "# and concatenating that to the Inception v3 CNN as the top layer.\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(conv_base)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(model.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 98304)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25166080  \n",
      "=================================================================\n",
      "Total params: 46,968,864\n",
      "Trainable params: 46,934,432\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View the output of the final CNN mode that leverages inception \n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Newly Trained Inception Model\n",
    "\n",
    " model.save(algorithmFolder + 'modeltestDKInception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Phase III - Prepare the RNN and extract features from the Inception model training. \n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function which will load the videos from the main directory and prepare them for processing in the RNN/LSTM\n",
    "# Please note that the model2 (proper connected Inception CNN) is used within this function! \n",
    "\n",
    "def extract_features_RNN(cat_dict, dir_path, cat_groups, sample_size):\n",
    "    import re\n",
    "    import cv2\n",
    "    \n",
    "    s = 0\n",
    "    \n",
    "    features = np.zeros(shape=(sample_size, video_frame_count , 256))\n",
    "    labels = np.zeros(shape=(sample_size, layer_count)) # original 3 label_count\n",
    "    frames = np.zeros(shape=(video_frame_count, horizontal_size, vertical_size, layer_count)) # original 3\n",
    "    \n",
    "    video_path = (f for f in os.listdir(dir_path) if not f.startswith('.'))\n",
    "    for cat in video_path:\n",
    "        print(cat, cat_dict[cat])\n",
    "        cat_dir = os.path.join(dir_path, cat)\n",
    "        video_files = (f for f in os.listdir(cat_dir) if not f.startswith('.'))\n",
    "        for f in video_files:\n",
    "        #for f in sorted(video_files)[1:]:\n",
    "            if s >= sample_size:\n",
    "                break\n",
    "            group_name = re.search('^\\w+_\\w+_g(\\d\\d)', f).group(1)\n",
    "            if group_name in cat_groups[cat]:\n",
    "                v = cv2.VideoCapture(os.path.join(cat_dir, f))\n",
    "                frame_count = int(v.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                frame_height = int(v.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                frame_width = int(v.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                if frame_count >= video_frame_count and frame_height == horizontal_size and frame_width == vertical_size:\n",
    "                    read_frames_idx = list(range(0, frame_count, frame_count))\n",
    "                    for i, idx in enumerate(read_frames_idx):\n",
    "                        v.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "                        success, image = v.read()\n",
    "                            #print(s, i, idx, success)\n",
    "                        if success:\n",
    "                            frames[i] = image / 255.\n",
    "                        else:\n",
    "                            print(\"ERROR\")\n",
    "                    features[s, :, :] = model2.predict(frames)\n",
    "                    labels[s, cat_dict[cat]] = 1\n",
    "                    print(s)\n",
    "                    s += 1\n",
    "                        \n",
    "    return s, features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the category group names\n",
    "\n",
    "def find_cat_groups(dir_name):\n",
    "    import re\n",
    "    \n",
    "    cat_groups = {}\n",
    "    \n",
    "    for cat in os.listdir(dir_name):\n",
    "        samples_dir = os.path.join(dir_name, cat)\n",
    "        cat_groups[cat] = {re.search('^(\\d+)', f).group(1) for f in os.listdir(samples_dir) if not f.startswith('.')}\n",
    "    \n",
    "    return cat_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional features to review\n",
    "\n",
    "cat_groups_train, cat_groups_validation = find_cat_groups(train_dir), find_cat_groups(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HorseRace': {'02',\n",
       "  '03',\n",
       "  '04',\n",
       "  '05',\n",
       "  '06',\n",
       "  '07',\n",
       "  '08',\n",
       "  '09',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25'},\n",
       " 'HorseRiding': {'01',\n",
       "  '02',\n",
       "  '03',\n",
       "  '04',\n",
       "  '06',\n",
       "  '07',\n",
       "  '09',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25'},\n",
       " 'YoYo': {'01',\n",
       "  '02',\n",
       "  '03',\n",
       "  '04',\n",
       "  '05',\n",
       "  '06',\n",
       "  '07',\n",
       "  '08',\n",
       "  '09',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '20',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the catgory of training\n",
    "\n",
    "cat_groups_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the category training # of entries for future use\n",
    "\n",
    "video_train_count = sum(map(len, cat_groups_train.values()))\n",
    "# print(video_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HorseRace': {'01', '17'}, 'HorseRiding': {'05', '13'}, 'YoYo': {'19', '21'}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the catgory of validation\n",
    "\n",
    "cat_groups_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the category testing # of entries for future use\n",
    "\n",
    "video_test_count= sum(map(len, cat_groups_validation.values()))\n",
    "# print(video_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that the length of the train and validation are identical\n",
    "\n",
    "len(cat_groups_train), len(cat_groups_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the categories in a dictionary that you train\n",
    "\n",
    "cat_dict = {cat_name: i for i, cat_name in enumerate(cat_groups_train.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HorseRace 0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "HorseRiding 1\n",
      "YoYo 2\n"
     ]
    }
   ],
   "source": [
    "# This is the RNN training procedure\n",
    "# Note: Remove Hard code from video_train_count and make dynamic\n",
    "\n",
    "\n",
    "size, features_rnn, labels_rnn = extract_features_RNN(cat_dict, Raw_Video_Source, cat_groups_train, video_train_count) # original 3104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the various features for the RNN training\n",
    "\n",
    "np.save(\"features_rnn\", features_rnn[:size,:,:])\n",
    "np.save(\"labels_rnn\", labels_rnn[:size,:])\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HorseRace 0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "HorseRiding 1\n",
      "YoYo 2\n"
     ]
    }
   ],
   "source": [
    "# This is the RNN validation procedure\n",
    "\n",
    "size_v, features_rnn_v, labels_rnn_v = extract_features_RNN(cat_dict, Raw_Video_Source, cat_groups_validation, video_test_count) #original is 237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the various features for the RNN training\n",
    "\n",
    "np.save(\"features_rnn_v.np\", features_rnn_v[:size_v,:,:])\n",
    "np.save(\"labels_rnn_v.np\", labels_rnn_v[:size_v,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68, 80, 256), (68, 3))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the various features\n",
    "\n",
    "features_rnn.shape, labels_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 80, 256), (6, 3))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the RNN various features for the validation\n",
    "\n",
    "features_rnn_v.shape, labels_rnn_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds the first value of a tuple\n",
    "\n",
    "Dense_Function = labels_rnn_v.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Phase IV - Build the LSTM algorithm and pass the RNN features as the parameters \n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Long Short Term Memory Algorithm (LSTM)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(video_frame_count, 256)))\n",
    "model.add(Dense(Dense_Function, activation='softmax')) # Original 3\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 6 samples\n",
      "Epoch 1/10\n",
      "68/68 [==============================] - 11s 165ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 9.7752e-06 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 6s 85ms/step - loss: 8.5323e-06 - acc: 1.0000 - val_loss: 7.3910e-06 - val_acc: 1.0000 loss: 8.6162e-06 - acc: 1\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 7s 98ms/step - loss: 6.4627e-06 - acc: 1.0000 - val_loss: 5.6029e-06 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 7s 96ms/step - loss: 4.8946e-06 - acc: 1.0000 - val_loss: 4.2915e-06 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 6s 84ms/step - loss: 3.8831e-06 - acc: 1.0000 - val_loss: 3.5763e-06 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 5s 80ms/step - loss: 3.2073e-06 - acc: 1.0000 - val_loss: 2.9802e-06 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 5s 80ms/step - loss: 2.6840e-06 - acc: 1.0000 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 6s 82ms/step - loss: 2.2659e-06 - acc: 1.0000 - val_loss: 2.1458e-06 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 6s 84ms/step - loss: 1.9784e-06 - acc: 1.0000 - val_loss: 1.7881e-06 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 5s 80ms/step - loss: 1.7268e-06 - acc: 1.0000 - val_loss: 1.6093e-06 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the LSTM model\n",
    "\n",
    "hist = model.fit(features_rnn, labels_rnn,\n",
    "                epochs=Epochs_LSTM, # 30 in the original\n",
    "                batch_size=1,\n",
    "                validation_data=(features_rnn_v, labels_rnn_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 200)               365600    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 366,203\n",
      "Trainable params: 366,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHlNJREFUeJzt3Xt4FfW97/H3R0CRmyBgVRBCrbsqIYEYQbeoeDlUrJeKtkq1Fa3SWrG26rOPVc7Rxxbb7a3W6rFSq62VQt1arVovrRZvtahBBES2QhU1ghgQ8YKXxv09f8wkrsRcVsLClWQ+r+dZT+bym5nvTJLPmvWbtWYpIjAzs2zYotgFmJnZZ8ehb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQzyBJ3SS9K2lYIdsWk6QvSCr4+48lHSxpZc7485L2zadtO7Z1vaTz2ru8WT66F7sAa52kd3NGewEfAh+n49+OiNltWV9EfAz0KXTbLIiILxZiPZJOAU6IiAk56z6lEOs2a4lDvxOIiPrQTc8kT4mIB5prL6l7RNR+FrWZtcZ/jx2Lu3e6AEk/lvQHSXMkvQOcIGlvSfMlvSVptaSrJPVI23eXFJJK0vGb0/n3SnpH0j8kjWhr23T+JEkvSNog6ReS/i5pajN151PjtyWtkLRe0lU5y3aT9DNJ6yT9EzikheMzQ9LcRtOukXRFOnyKpGXp/vwzPQtvbl3Vkiakw70k/S6tbSmwRxPbfTFd71JJR6TTRwFXA/umXWdrc47thTnLfyfd93WS7pC0Qz7Hpi3Hua4eSQ9IelPS65L+I2c7/yc9Jm9LqpK0Y1NdaZIeq/s9p8fzkXQ7bwIzJO0iaV66L2vT47ZNzvLD032sSef/XFLPtObdctrtIGmjpIHN7a+1IiL86EQPYCVwcKNpPwY+Ag4neSLfGtgTGEfyau7zwAvA9LR9dyCAknT8ZmAtUAn0AP4A3NyOttsB7wBHpvPOAv4FTG1mX/Kp8U/ANkAJ8GbdvgPTgaXAUGAg8Ejy59zkdj4PvAv0zln3G0BlOn542kbAgcD7QFk672BgZc66qoEJ6fBlwEPAAGA48Fyjtl8Ddkh/J19Pa/hcOu8U4KFGdd4MXJgOT0xrHA30BP4f8Ld8jk0bj/M2wBrgTGAroB8wNp33Q2ARsEu6D6OBbYEvND7WwGN1v+d032qB04BuJH+P/wYcBGyZ/p38HbgsZ3+eTY9n77T9Pum8WcDMnO2cDdxe7P/DzvwoegF+tPEX1nzo/62V5c4B/isdbirIf5nT9gjg2Xa0PRl4NGeegNU0E/p51rhXzvw/Auekw4+QdHPVzTu0cRA1Wvd84Ovp8CTghRba3g2cng63FPqv5P4ugO/mtm1ivc8CX06HWwv93wIX58zrR3IdZ2hrx6aNx/kbQFUz7f5ZV2+j6fmE/out1HAM8FQ6vC/wOtCtiXb7AC8BSsefASYX+v8qSw9373Qdr+aOSNpV0p/Tl+tvAxcBg1pY/vWc4Y20fPG2ubY75tYRyX9pdXMrybPGvLYFvNxCvQC/B6akw18H6i9+SzpM0hNp98ZbJGfZLR2rOju0VIOkqZIWpV0UbwG75rleSPavfn0R8TawHhiS0yav31krx3knYEUzNexEEvzt0fjvcXtJt0h6La3hN41qWBnJmwYaiIi/k7xqGC+pFBgG/LmdNRnu0+9KGr9d8TqSM8svREQ/4P+SnHlvTqtJzkQBkCQahlRjm1LjapKwqNPaW0r/ABwsaShJ99Pv0xq3Bm4FfkLS9dIf+EuedbzeXA2SPg9cS9LFMTBd73/nrLe1t5euIukyqltfX5JupNfyqKuxlo7zq8DOzSzX3Lz30pp65UzbvlGbxvv3nyTvOhuV1jC1UQ3DJXVrpo6bgBNIXpXcEhEfNtPO8uDQ77r6AhuA99ILYd/+DLZ5N1Ah6XBJ3Un6iQdvphpvAb4vaUh6Ue9/t9Q4ItaQdEHcCDwfEcvTWVuR9DPXAB9LOoyk7znfGs6T1F/J5xim58zrQxJ8NSTPf6eQnOnXWQMMzb2g2sgc4FuSyiRtRfKk9GhENPvKqQUtHec7gWGSpkvaUlI/SWPTedcDP5a0sxKjJW1L8mT3OskbBrpJmkbOE1QLNbwHbJC0E0kXU51/AOuAi5VcHN9a0j45839H0h30dZInANsEDv2u62zgRJILq9eRnOluVmmwHgtcQfJPvDOwkOQMr9A1Xgs8CCwBniI5W2/N70n66H+fU/NbwA+A20kuhh5D8uSVjwtIXnGsBO4lJ5AiYjFwFfBk2mZX4ImcZf8KLAfWSMrtpqlb/j6Sbpjb0+WHAcfnWVdjzR7niNgA/C/gaJILxy8A+6ezLwXuIDnOb5NcVO2ZdtudCpxHclH/C432rSkXAGNJnnzuBG7LqaEWOAzYjeSs/xWS30Pd/JUkv+ePIuLxNu67NVJ3ccSs4NKX66uAYyLi0WLXY52XpJtILg5fWOxaOjt/OMsKStIhJC/XPyB5y18tydmuWbuk10eOBEYVu5auwN07VmjjgRdJXvYfAnzFF96svST9hOSzAhdHxCvFrqcrcPeOmVmG+EzfzCxDOlyf/qBBg6KkpKTYZZiZdSoLFixYGxEtvUUa6IChX1JSQlVVVbHLMDPrVCS19ql0wN07ZmaZ4tA3M8sQh76ZWYZ0uD59Myuef/3rX1RXV/PBBx8UuxRrRs+ePRk6dCg9ejR326aWOfTNrF51dTV9+/alpKSE5Cap1pFEBOvWraO6upoRI0a0vkAT3L1jZvU++OADBg4c6MDvoCQxcODATXol5tA3swYc+B3bpv5+HPpmZhni0DezDmPdunWMHj2a0aNHs/322zNkyJD68Y8++iivdZx00kk8//zzLba55pprmD17dottuipfyDWzdps9G84/H155BYYNg5kz4fj2ftULMHDgQJ555hkALrzwQvr06cM555zToE39F3xv0fQ564033tjqdk4//fT2F9nJ+UzfzNpl9myYNg1efhkikp/TpiXTC23FihWUlpbyne98h4qKClavXs20adOorKxk5MiRXHTRRfVtx48fzzPPPENtbS39+/fn3HPPpby8nL333ps33ngDgBkzZnDllVfWtz/33HMZO3YsX/ziF3n88eTLud577z2OPvpoysvLmTJlCpWVlfVPSLkuuOAC9txzz/r66u5c/MILL3DggQdSXl5ORUUFK1euBODiiy9m1KhRlJeXc/755xf+YLXCoW9m7XL++bBxY8NpGzcm0zeH5557jm9961ssXLiQIUOG8NOf/pSqqioWLVrEX//6V5577rlPLbNhwwb2339/Fi1axN57780NN9zQ5LojgieffJJLL720/gnkF7/4Bdtvvz2LFi3i3HPPZeHChU0ue+aZZ/LUU0+xZMkSNmzYwH333QfAlClT+MEPfsCiRYt4/PHH2W677bjrrru49957efLJJ1m0aBFnn312gY5O/hz6ZtYurzTzlSbNTd9UO++8M3vuuWf9+Jw5c6ioqKCiooJly5Y1Gfpbb701kyZNAmCPPfaoP9tubPLkyZ9q89hjj3HccccBUF5ezsiRI5tc9sEHH2Ts2LGUl5fz8MMPs3TpUtavX8/atWs5/PDDgeQDVb169eKBBx7g5JNPZuuttwZg2223bfuB2ETu0zezdhk2LOnSaWr65tC7d+/64eXLl/Pzn/+cJ598kv79+3PCCSc0+d71Lbfcsn64W7du1NbWNrnurbba6lNt8vmCqY0bNzJ9+nSefvpphgwZwowZM+rraOqtlRFR9LfE+kzfzNpl5kzo1avhtF69kumb29tvv03fvn3p168fq1ev5v777y/4NsaPH88tt9wCwJIlS5p8JfH++++zxRZbMGjQIN555x1uu+02AAYMGMCgQYO46667gORDbxs3bmTixIn8+te/5v333wfgzTffLHjdrXHom1m7HH88zJoFw4eDlPycNWvT3r2Tr4qKCnbffXdKS0s59dRT2WeffQq+jTPOOIPXXnuNsrIyLr/8ckpLS9lmm20atBk4cCAnnngipaWlHHXUUYwbN65+3uzZs7n88sspKytj/Pjx1NTUcNhhh3HIIYdQWVnJ6NGj+dnPflbwulvT4b4jt7KyMvwlKmbFsWzZMnbbbbdil9Eh1NbWUltbS8+ePVm+fDkTJ05k+fLldO9e/F7xpn5PkhZERGVryxa/ejOzDujdd9/loIMOora2lojguuuu6xCBv6k6/x6YmW0G/fv3Z8GCBcUuo+Dcp29mliEOfTOzDHHom5lliEPfzCxDHPpm1mFMmDDhUx+0uvLKK/nud7/b4nJ9+vQBYNWqVRxzzDHNrru1t4NfeeWVbMy5odChhx7KW2+9lU/pnYZD38w6jClTpjB37twG0+bOncuUKVPyWn7HHXfk1ltvbff2G4f+PffcQ//+/du9vo6o1dCXdIOkNyQ928x8SbpK0gpJiyVVNJrfT9Jrkq4uVNFm1jUdc8wx3H333Xz44YcArFy5klWrVjF+/Pj6981XVFQwatQo/vSnP31q+ZUrV1JaWgokt0g47rjjKCsr49hjj62/9QHAaaedVn9b5gsuuACAq666ilWrVnHAAQdwwAEHAFBSUsLatWsBuOKKKygtLaW0tLT+tswrV65kt91249RTT2XkyJFMnDixwXbq3HXXXYwbN44xY8Zw8MEHs2bNGiD5LMBJJ53EqFGjKCsrq7+Nw3333UdFRQXl5eUcdNBBBTm2dfJ5n/5vgKuBm5qZPwnYJX2MA65Nf9b5EfBw+0s0s2L4/vehidvHb5LRoyHNyyYNHDiQsWPHct9993HkkUcyd+5cjj32WCTRs2dPbr/9dvr168fatWvZa6+9OOKII5q9gdm1115Lr169WLx4MYsXL6ai4pPz0ZkzZ7Ltttvy8ccfc9BBB7F48WK+973vccUVVzBv3jwGDRrUYF0LFizgxhtv5IknniAiGDduHPvvvz8DBgxg+fLlzJkzh1/96ld87Wtf47bbbuOEE05osPz48eOZP38+krj++uu55JJLuPzyy/nRj37ENttsw5IlSwBYv349NTU1nHrqqTzyyCOMGDGi4PfnafVMPyIeAVra6pHATZGYD/SXtAOApD2AzwF/KUSxZtb15Xbx5HbtRATnnXceZWVlHHzwwbz22mv1Z8xNeeSRR+rDt6ysjLKysvp5t9xyCxUVFYwZM4alS5c2eTO1XI899hhHHXUUvXv3pk+fPkyePJlHH30UgBEjRjB69Gig+ds3V1dX86UvfYlRo0Zx6aWXsnTpUgAeeOCBBt/iNWDAAObPn89+++3HiBEjgMLffrkQn8gdAryaM14NDJG0Brgc+AbQ4usTSdOAaQDDNtd9Wc2sTVo6I9+cvvKVr3DWWWfx9NNP8/7779efoc+ePZuamhoWLFhAjx49KCkpafJ2yrmaehXw0ksvcdlll/HUU08xYMAApk6d2up6WrpHWd1tmSG5NXNT3TtnnHEGZ511FkcccQQPPfQQF154Yf16G9e4uW+/XIgLuU1VF8B3gXsi4tUm5jdsHDErIiojonLw4MEFKMnMOqs+ffowYcIETj755AYXcDds2MB2221Hjx49mDdvHi83dTP/HPvtt1/9l58/++yzLF68GEhuy9y7d2+22WYb1qxZw7333lu/TN++fXnnnXeaXNcdd9zBxo0bee+997j99tvZd999896nDRs2MGTIEAB++9vf1k+fOHEiV1/9yeXO9evXs/fee/Pwww/z0ksvAYW//XIhQr8a2ClnfCiwCtgbmC5pJXAZ8E1JPy3A9sysi5syZQqLFi2q/+YqgOOPP56qqioqKyuZPXs2u+66a4vrOO2003j33XcpKyvjkksuYezYsUDyLVhjxoxh5MiRnHzyyQ1uyzxt2jQmTZpUfyG3TkVFBVOnTmXs2LGMGzeOU045hTFjxuS9PxdeeCFf/epX2XfffRtcL5gxYwbr16+ntLSU8vJy5s2bx+DBg5k1axaTJ0+mvLycY489Nu/t5COvWytLKgHujojSJuZ9GZgOHEpyAfeqiBjbqM1UoDIipre2Ld9a2ax4fGvlzmGz3lpZ0hxgAjBIUjVwAdADICJ+CdxDEvgrgI3ASW2s38zMPiOthn5EtPipiEheKpzeSpvfkLz108zMisifyDWzBjrat+lZQ5v6+3Hom1m9nj17sm7dOgd/BxURrFu3jp49e7Z7Hf7mLDOrN3ToUKqrq6mpqSl2KdaMnj17MnTo0HYv79A3s3o9evSo/ySodU3u3jEzyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhrQa+pJukPSGpGebmS9JV0laIWmxpIp0+mhJ/5C0NJ1+bKGLNzOztsnnTP83wCEtzJ8E7JI+pgHXptM3At+MiJHp8ldK6t/+Us3MbFN1b61BRDwiqaSFJkcCN0VEAPMl9Ze0Q0S8kLOOVZLeAAYDb21izWZm1k6F6NMfAryaM16dTqsnaSywJfDPAmzPzMzaqRChryamRf1MaQfgd8BJEfE/Ta5AmiapSlJVTU1NAUoyM7OmFCL0q4GdcsaHAqsAJPUD/gzMiIj5za0gImZFRGVEVA4ePLgAJZmZWVMKEfp3At9M38WzF7AhIlZL2hK4naS//78KsB0zM9tErV7IlTQHmAAMklQNXAD0AIiIXwL3AIcCK0jesXNSuujXgP2AgZKmptOmRsQzBazfzMzaIJ9370xpZX4Apzcx/Wbg5vaXZmZmheZP5JqZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIa2GvqQbJL0h6dlm5kvSVZJWSFosqSJn3omSlqePEwtZeGOzZ0NJCWyxRfJz9uzNubWOW4PrcB2doY6OUENm64iIFh/AfkAF8Gwz8w8F7gUE7AU8kU7fFngx/TkgHR7Q2vb22GOPaKubb47o1SsCPnn06pVM/6x0hBpch+voDHV0hBq6Yh1AVbSSrxGBkrYtk1QC3B0RpU3Muw54KCLmpOPPAxPqHhHx7abaNaeysjKqqqparSlXSQm8/PKnp2+1Fey1V5tW1W7z58OHHxa3BtfhOjpDHR2hhs5Qx/DhsHJl/uuRtCAiKltrV4g+/SHAqznj1em05qZ/iqRpkqokVdXU1LS5gFdeaXp6Uwdyc2luW59lDa7DdXSGOjpCDZ2hjuZybVN1L8A61MS0aGH6pydGzAJmQXKm39YChg1r+kx/+HB46KG2rq19mnu18VnW4DpcR2eooyPU0BnqGDZs82yvEGf61cBOOeNDgVUtTC+4mTOhV6+G03r1SqZ/VjpCDa7DdXSGOjpCDZmuI5+Of6CE5i/kfpmGF3KfjE8u5L5EchF3QDq8bWvbas+F3Ijkosfw4RFS8vOzvhjTUWpwHa6jM9TREWroanVQqAu5kuaQXJQdBKwBLgB6pE8Yv5Qk4GrgEGAjcFJEVKXLngycl65qZkTc2NqTUHsu5JqZZV2+F3Jb7dOPiCmtzA/g9Gbm3QDc0No2zMzss+FP5JqZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMiSv0Jd0iKTnJa2QdG4T84dLelDSYkkPSRqaM+8SSUslLZN0lSQVcgfMzCx/rYa+pG7ANcAkYHdgiqTdGzW7DLgpIsqAi4CfpMv+O7APUAaUAnsC+xesejMza5N8zvTHAisi4sWI+AiYCxzZqM3uwIPp8Lyc+QH0BLYEtgJ6AGs2tWgzM2uffEJ/CPBqznh1Oi3XIuDodPgooK+kgRHxD5IngdXp4/6IWLZpJZuZWXvlE/pN9cFHo/FzgP0lLSTpvnkNqJX0BWA3YCjJE8WBkvb71AakaZKqJFXV1NS0aQfMzCx/+YR+NbBTzvhQYFVug4hYFRGTI2IMcH46bQPJWf/8iHg3It4F7gX2aryBiJgVEZURUTl48OB27oqZmbUmn9B/CthF0ghJWwLHAXfmNpA0SFLdun4I3JAOv0LyCqC7pB4krwLcvWNmViSthn5E1ALTgftJAvuWiFgq6SJJR6TNJgDPS3oB+BwwM51+K/BPYAlJv/+iiLirsLtgZmb5UkTj7vniqqysjKqqqmKXYWbWqUhaEBGVrbXzJ3LNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0Dczy5C8Ql/SIZKel7RC0rlNzB8u6UFJiyU9JGlozrxhkv4iaZmk5ySVFK58MzNri1ZDX1I34BpgErA7MEXS7o2aXQbcFBFlwEXAT3Lm3QRcGhG7AWOBNwpRuJmZtV0+Z/pjgRUR8WJEfATMBY5s1GZ34MF0eF7d/PTJoXtE/BUgIt6NiI0FqdzMzNosn9AfAryaM16dTsu1CDg6HT4K6CtpIPBvwFuS/ihpoaRL01cODUiaJqlKUlVNTU3b98LMzPKST+iriWnRaPwcYH9JC4H9gdeAWqA7sG86f0/g88DUT60sYlZEVEZE5eDBg/Ov3szM2iSf0K8GdsoZHwqsym0QEasiYnJEjAHOT6dtSJddmHYN1QJ3ABUFqdzMzNosn9B/CthF0ghJWwLHAXfmNpA0SFLdun4I3JCz7ABJdafvBwLPbXrZZmbWHq2GfnqGPh24H1gG3BIRSyVdJOmItNkE4HlJLwCfA2amy35M0rXzoKQlJF1Fvyr4XpiZWV4U0bh7vrgqKyujqqqq2GWYmXUqkhZERGVr7fyJXDOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliGKiGLX0ICkGuDlTVjFIGBtgcrp7HwsGvLxaMjH4xNd4VgMj4jBrTXqcKG/qSRVRURlsevoCHwsGvLxaMjH4xNZOhbu3jEzyxCHvplZhnTF0J9V7AI6EB+Lhnw8GvLx+ERmjkWX69M3M7PmdcUzfTMza4ZD38wsQ7pM6Es6RNLzklZIOrfY9RSTpJ0kzZO0TNJSSWcWu6Zik9RN0kJJdxe7lmKT1F/SrZL+O/0b2bvYNRWTpB+k/yfPSpojqWexa9qcukToS+oGXANMAnYHpkjavbhVFVUtcHZE7AbsBZye8eMBcCawrNhFdBA/B+6LiF2BcjJ8XCQNAb4HVEZEKdANOK64VW1eXSL0gbHAioh4MSI+AuYCRxa5pqKJiNUR8XQ6/A7JP/WQ4lZVPJKGAl8Gri92LcUmqR+wH/BrgIj4KCLeKm5VRdcd2FpSd6AXsKrI9WxWXSX0hwCv5oxXk+GQyyWpBBgDPFHcSorqSuA/gP8pdiEdwOeBGuDGtLvrekm9i11UsUTEa8BlwCvAamBDRPyluFVtXl0l9NXEtMy/F1VSH+A24PsR8Xax6ykGSYcBb0TEgmLX0kF0ByqAayNiDPAekNlrYJIGkPQKjAB2BHpLOqG4VW1eXSX0q4GdcsaH0sVforVGUg+SwJ8dEX8sdj1FtA9whKSVJN1+B0q6ubglFVU1UB0Rda/8biV5Esiqg4GXIqImIv4F/BH49yLXtFl1ldB/CthF0ghJW5JciLmzyDUVjSSR9Nkui4gril1PMUXEDyNiaESUkPxd/C0iuvSZXEsi4nXgVUlfTCcdBDxXxJKK7RVgL0m90v+bg+jiF7a7F7uAQoiIWknTgftJrr7fEBFLi1xWMe0DfANYIumZdNp5EXFPEWuyjuMMYHZ6gvQicFKR6ymaiHhC0q3A0yTveltIF78lg2/DYGaWIV2le8fMzPLg0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZcj/BziaxNosqEhFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostic plots for the CNN algorithm accuracy\n",
    "\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Fully Trained LSTM model\n",
    "\n",
    "model.save(algorithmFolder + 'modeltestDKLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
